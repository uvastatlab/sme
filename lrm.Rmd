---
title: "Logistic Regression Models"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
bibliography: refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

### Logistic regression with no predictors (intercept only)

100 Hershey's Kisses are put into a large cup and dumped on a table. We want to estimate the proportion of Kisses we can expect to land on their base. [@bilder2015] In our experiment we observe 39 out of 100. What is the 95% confidence interval on the proportion?

```{r}
prop.test(x = 39, n = 100)
```

To get just the confidence interval:

```{r}
pout <- prop.test(x = 39, n = 100)
pout$conf.int
```

This can be analyzed as an intercept-only binary logistic regression model. The confidence interval is slightly different.

```{r}
m <- glm(cbind(39, 100-39) ~ 1, family = binomial)
plogis(confint(m))
```

There are many confidence intervals that can be calculated for proportions. The binom package calculates 11 of them. [@binom]

```{r}
library(binom)
binom.confint(x = 39, n = 100)
```

The "prop.test" and "profile" versions are the two we calculated above. 

### Logistic regression with numeric predictors (1)

The `malaria` data frame from the ISwR package has 100 rows and 4 columns. It contains data on a sample of 100 children aged 3â€“15 years from a village in Ghana. Based on observations during the study period, the children were categorized into two groups: individuals with and without symptoms of malaria. Model the risk of malaria (`mal`) as a function of age (`age`) and log-transformed antibody levels (`log(ab)`).  [@ISwR]

```{r}
library(ISwR)
data("malaria")
```

To start, let's take a quick look at the summary of the data using the `summary()` function:

```{r}
summary(malaria)
```

Looking at the summary, we can see that mal takes the values 0 and 1. The mean of mal is 0.27, which indicates that 27% of the data take the value 1, meaning 27% of children monitored showed symptoms of malaria. 

We can see that age ranges from 3 to 15 and is slightly left-skewed. We can tell the skewness by comparing the median to the mean. Here, the median, 9.00, is slightly larger than the mean, 8.86. This indicates that more of the data is below the mean -- the distribution is pulled out to the left, meaning there are slightly more younger children in this dataset. 

From the summary we can also see that ab is very skewed, but in the opposite direction as age. Ab represents the antibody levels of the subjects and ranges from 2.0 to 2066.0. The median of ab, 111.0, is much smaller than the mean, 311.5. This indicates that ab is right-skewed. If we look at the 3rd quantile, we can see that 75% of the data is below 373.8. The maximum value of 2066.0 is much much larger than the 3rd quantile value, which may hint that the 2066.0 could be an outlier. 

Looking at a box plot of the ab can give us a good visualization of this skewness and spread of the data. Here we plot the distribution of ab by mal and log(ab) by mal.

```{r}
boxplot(ab ~ mal, data = malaria)

boxplot(log(ab) ~ mal, data = malaria)
```

In the first box plot (ab by mal), because of the spread of the data, it appears very sqiushed and hard to interpret. We can see that children who did show symptoms of malaria (mal = 1) tend to have a lower antibody count while those who did not show symptoms (mal = 0) tend to have a higher antibody count. We can also see the right-skewness of the data. 

The log transformed ab data is much clearer. We can see that same trend of lower antibody count for those who showed symptoms of malaria. With this plot we can get a feel for the values of the data: for those who showed no symptoms of malaria, we can see that 50% of the data falls between log(ab) = 4 and 6, whereas 50% of the data for those who did show symptoms of malaria falls between about log(ab) = 3 and 4. 

We can also look at how age varies based on malaria symptoms: 

```{r}
library(ggplot2)

malaria$group = ifelse(malaria$mal == 0, 'no symptoms', 'symptoms')

ggplot(malaria, aes(x=age, fill = group)) + 
  geom_histogram(binwidth=1, color="black",) + 
  scale_fill_manual(values = c('no symptoms' = 'gray', 
                               'symptoms' = 'cornflowerblue'))
```

From the histogram, we can see that the ages of subjects are more or less uniformly spread from 3 to 15. From the box plot, we can see that subjects who showed symptoms of malaria tended to be of a younger age. 

Now let's build our model. We will use the `glm()` function. `glm()` is used to fit a generalized linear model to the data. To specify logistic regression, in the argument we set the `family = binomial(link = "logit")`. 

```{r}
lrm <- glm(mal ~ age + log(ab), family = binomial(link = "logit"), data = malaria)
```

Now we look at a summary of the model:

```{r}
summary(lrm)
```

Next we assess model fit:

```{r}
anova(lrm, test = "Chisq")
```

This shows that the model including age is a slightly better fit than the null model (intercept only). The model including both age and log(ab) is a better fit ($\chi^2(1,N = 100) = 15.63, p < .001$) than the model only containing age. In general, a predictor that contributes to a model will reduce deviance by more than 1 or 2 units.

We can also assess fit of the model by comparing it to the *saturated model*, or a model with perfect fit.

```{r}
vcdExtra::LRstats(m)
```

The null of the test is the model is no different from the saturated model. A low p-value rejects the null. Here the p-value is pretty high, so we might have some confidence in using this model to predict the probability of malaria risk.

Before interpreting the model, we can assess model error by looking at a plot of residuals vs. "Hat-values". Residuals = observed response - predicted probability. Hat-values measure leverage.

```{r}
car::influencePlot(lrm)
```  

The size of points corresponds to Cook's Distance.  Points to the right of the dotted vertical line have high Hat-Values and could be influencing the fit of the model. Hat-Values measure how far away a subjects predictor values are from the center of the predictor space. Cook's D measures influence. Big values (ie, big Bubbles) could be influencing the estimated coefficients.

By default the 4 most extreme points are labeled. We can investigate those as follows:

```{r}
malaria[c(13,19,35, 78),]
```

These points have very high and very low levels of ab. The two highest are unusual because most subjects with mal = 1 have low ab values.

We can also look at the model coefficients and confidence intervals. 

```{r}
lrm$coefficients
confint(lrm)
```

If we look at the confidence intervals for the coefficients in our model, we can see reasonable ranges of values for the coefficients. The reasonable range of values for the age coefficient is -0.202 to 0.066. Note this range is small and includes 0, which implies that the effect of age on mal is small and we can't be sure if the effect is positive or negative. 

The reasonable range of values for log(ab) is -1.099 to -0.324. This range is entirely negative and suggests that lower antibody count is associated with higher risk of malaria. We can exponentiate this confidence interval to get an odds ratio (the ratio of the odds of showing symptoms to the odds of not showing symptoms of malaria).

```{r}
exp(confint(lrm)["log(ab)",])
```

Here we can see that the odds ratio is less than 1, which indicates that as log(ab) increases, the odds of malaria decreases. For every one-unit increase of log(ab), the odds of malaria decreases by anywhere from 28% to 67%. (Note: 1 - 0.33 = 0.67 and 1 - 0.72 = 0.28.) 

Now we can assess the accuracy of the model we built. 

```{r}
anova(lrm, test = "Chisq")
```





If we wanted to, we could have split the data into training and testing data:

```{r}
set.seed(1)  # make reproducible
i <- sample(x = nrow(malaria), size = 0.75*floor(nrow(malaria)))
malaria.train <- malaria[i,]
malaria.test <- malaria[-i,]
```

We can then test our model on the training data and see how well it performs. 

```{r}
prediction <- predict(lrm, newdata = malaria.test, type="response")
```

### Logistic regression with numeric predictors (2)

The `pima` data frame from the faraway package contains data on 768 adult female Pima Indians living near Phoenix [@faraway]. This data was collected by [The National Institute of Diabetes and Digestive and Kidney Diseases](https://www.niddk.nih.gov/). The purpose of the study was to investigate factors related to diabetes. The variable `test` indicates whether the patient showed signs of diabetes (coded 0 if negative, 1 if positive). Model `test` as a function of all other predictors.

```{r}
library(faraway)
data("pima")
```

What is the difference in odds of testing positive for diabetes for a subject with BMI in the first quartile compared to a subject with BMI at the third quartile? [@faraway_book]

```{r eval=FALSE}
library(emmeans)
bmi_vals <- quantile(pima$bmi, probs = c(0.25,0.75))
rg <- ref_grid(m, at = list(bmi = bmi_vals))
emmeans(rg, specs = "bmi", type = "response") |>
  contrast("pairwise")
```


### Ordered logistic regression

The `Vietnam` data frame in the vcdExtra package [@vcdextra] contains survey data from 1967 on student opinions of the Vietnam War. Students were asked to indicate which policy out of A, B, C or D they supported. The response categories were:

- A: Defeat North Vietnam by widespread bombing and land invasion
- B: Maintain the present policy
- C: De-escalate military activity, stop bombing and begin negotiations
- D: Withdraw military forces Immediately

These are ordered levels, moving from very pro-war (A) to anti-war (D). Fit a proportional odds model to the data, modeling `response` as a function of `sex`, `year`, and their interaction. [@friendly2016] (`year` is an integer ranging from 1 - 5, corresponding to Freshmen, Sophomore, Junior, Senior, and Grad student.) 

```{r}
library(vcdExtra)
data("Vietnam")
```

This will require using the `weights` argument with the `polr()` function. [@MASS]


### References
