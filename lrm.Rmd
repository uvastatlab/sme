---
title: "Logistic Regression Models"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
bibliography: refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, comment = '')
```

### Logistic regression with no predictors (intercept only)

100 Hershey's Kisses are put into a large cup and dumped on a table. We want to estimate the proportion of Kisses we can expect to land on their base. [@bilder2015] In our experiment we observe 39 out of 100. What is the 95% confidence interval on the proportion?

We can calculate both the estimated proportion and the 95% confidence interval using the `prop.test()` function. We use the `x` argument to specify the number of "successes" and the `n` argument to specify the number of "trials". Clearly the estimated proportion is 39/100 = 0.39. The 95% confidence interval is reported as [0.296, 0.493]

```{r}
prop.test(x = 39, n = 100)
```

To extract just the confidence interval we can save the result of the `prop.test()` function and access the `conf.int` element:

```{r}
pout <- prop.test(x = 39, n = 100)
pout$conf.int
```

This can also be analyzed as an intercept-only binary logistic regression model using the `glm()` function. To carry this out we create a 1 x 2 matrix using the `cbind()` function with successes in the first column and failures in the second column. We then model the successes and failures as a function of the number one. This is R's syntax for fitting an intercept-only model. Notice we also set `family = binomial` to tell the `glm()` that our response is binary. To extract the confidence interval, we save the modeling output to an object we name "m"  and call `confint()` function on it. To get probabilities, we use the `plogis()` function, which converts log-odds to probabilities. (Binary logistic regression models probabilities on the log-odds scale.) The resulting confidence interval is slightly different than what we calculated above because `confint()` uses the profile likelihood method.

```{r}
m <- glm(cbind(39, 100-39) ~ 1, family = binomial)
plogis(confint(m))
```

There are many confidence intervals that can be calculated for proportions. The binom package calculates 11 of them. [@binom]

```{r}
library(binom)
binom.confint(x = 39, n = 100)
```

The "prop.test" row shows the first CI we calculated using `prop.test()`. The CI in the "profile" row is slightly different from what we calculated using the `confint()` function on the glm model object. The method is the same but the difference is due to the different default profile settings in the `confint()` and `binom.confint()` functions. 

When an estimated proportion is not near 0 or 1 it hardly matters how you estimate the confidence interval. However when your proportion is at the boundary, the confidence intervals can vary dramatically. For example, observe the wide variety of confidence intervals for the estimated proportion of 0.01. The first two methods return estimates with a lower bound below 0.

```{r}
binom.confint(x = 1, n = 100)
```


### Logistic regression with numeric predictors (1)

The `malaria` data frame from the ISwR package has 100 rows and 4 columns. It contains data on a sample of 100 children aged 3–15 years from a village in Ghana. Based on observations during the study period, the children were categorized into two groups: individuals with and without symptoms of malaria. Model the risk of malaria (`mal`) as a function of age (`age`) and log-transformed antibody levels (`log(ab)`).  [@ISwR]

```{r}
library(ISwR)
data("malaria")
```

To start, let's take a quick look at the summary of the data using the `summary()` function:

```{r}
summary(malaria)
```

Looking at the summary, we can see that mal takes the values 0 and 1. The mean of mal is 0.27, which indicates that 27% of the data take the value 1, meaning 27% of children monitored showed symptoms of malaria. 

We can see that age ranges from 3 to 15 and is slightly left-skewed. We can tell the skewness by comparing the median to the mean. Here, the median, 9.00, is slightly larger than the mean, 8.86. This indicates that more of the data is below the mean -- the distribution is pulled out to the left, meaning there are slightly more younger children in this dataset. 

From the summary we can also see that ab is very skewed, but in the opposite direction as age. Ab represents the antibody levels of the subjects and ranges from 2.0 to 2066.0. The median of ab, 111.0, is much smaller than the mean, 311.5. This indicates that ab is right-skewed. If we look at the 3rd quantile, we can see that 75% of the data is below 373.8. The maximum value of 2066.0 is much much larger than the 3rd quantile value, which may hint that the 2066.0 could be an outlier. 

Looking at a box plot of the ab can give us a good visualization of this skewness and spread of the data. Here we plot the distribution of ab by mal and log(ab) by mal.

```{r}
boxplot(ab ~ mal, data = malaria)

boxplot(log(ab) ~ mal, data = malaria)
```

In the first box plot (ab by mal), because of the spread of the data, it appears very sqiushed and hard to interpret. We can see that children who did show symptoms of malaria (mal = 1) tend to have a lower antibody count while those who did not show symptoms (mal = 0) tend to have a higher antibody count. We can also see the right-skewness of the data. 

The log transformed ab data is much clearer. We can see that same trend of lower antibody count for those who showed symptoms of malaria. With this plot we can get a feel for the values of the data: for those who showed no symptoms of malaria, we can see that 50% of the data falls between log(ab) = 4 and 6, whereas 50% of the data for those who did show symptoms of malaria falls between about log(ab) = 3 and 4. 

We can also look at how age varies based on malaria symptoms: 

```{r}
library(ggplot2)

malaria$group = ifelse(malaria$mal == 0, 'no symptoms', 'symptoms')

ggplot(malaria, aes(x=age, fill = group)) + 
  geom_histogram(binwidth=1, color="black",) + 
  scale_fill_manual(values = c('no symptoms' = 'gray', 
                               'symptoms' = 'cornflowerblue'))
```

From the histogram, we can see that the ages of subjects are more or less uniformly spread from 3 to 15. From the box plot, we can see that subjects who showed symptoms of malaria tended to be of a younger age. 

Now let's build our model. We will use the `glm()` function. `glm()` is used to fit a generalized linear model to the data. To specify logistic regression, in the argument we set the `family = binomial(link = "logit")`. 

```{r}
lrm <- glm(mal ~ age + log(ab), family = binomial(link = "logit"), data = malaria)
```

Now we look at a summary of the model:

```{r}
summary(lrm)
```

Next we assess model fit:

```{r}
anova(lrm, test = "Chisq")
```

This test helps us to determine if predictors reduce model deviance. The first line of this output shows the null model containing only the intercept -- it uses the observed proportion of subjects at risk of malaria. The second line shows a model including age. We can see that this has a slightly better fit than the null model because the deviance reduced from about 116 to about 113. The next row shows the model including both age and log(ab), and we can see that this is an even better fit ($\chi^2(1,N = 100) = 15.63, p < .001$) than the model only containing age. Here the deviance dropped down to about 98. In general, a predictor that contributes to a model will reduce deviance by more than 1 or 2 units.

We can also assess fit of the model by comparing it to the *saturated model*, or a model with perfect fit.

```{r}
vcdExtra::LRstats(lrm)
```

The null hypothesis of this test is that the model is no different from the saturated model. A low p-value rejects the null. Here the p-value is pretty high, so we might have some confidence in using this model to predict the probability of malaria risk.

Before interpreting the model, we can assess model error by looking at a plot of residuals vs. "Hat-values". Residuals = observed response - predicted probability. Hat-values measure leverage.

```{r}
car::influencePlot(lrm)
```  

The size of points corresponds to Cook's Distance.  Points to the right of the dotted vertical line have high Hat-Values and could be influencing the fit of the model. Hat-Values measure how far away a subjects predictor values are from the center of the predictor space. Cook's D measures influence. Big values (ie, big Bubbles) could be influencing the estimated coefficients.

By default the 4 most extreme points are labeled. We can investigate those as follows:

```{r}
malaria[c(13,19,35, 78),]
```

These points have very high and very low levels of ab. The two highest are unusual because most subjects with mal = 1 have low ab values.

We can also look at the model coefficients and confidence intervals. 

```{r}
lrm$coefficients
confint(lrm)
```

If we look at the confidence intervals for the coefficients in our model, we can see reasonable ranges of values for the coefficients. The reasonable range of values for the age coefficient is -0.202 to 0.066. Note this range is small and includes 0, which implies that the effect of age on mal is small and we can't be sure if the effect is positive or negative. 

The reasonable range of values for log(ab) is -1.099 to -0.324. This range is entirely negative and suggests that lower antibody count is associated with higher risk of malaria. We can exponentiate this confidence interval to get an odds ratio (the ratio of the odds of showing symptoms to the odds of not showing symptoms of malaria).

```{r}
exp(confint(lrm)["log(ab)",])
```

Here we can see that the odds ratio is less than 1, which indicates that as log(ab) increases, the odds of malaria decreases. For every one-unit increase of log(ab), the odds of malaria decreases by anywhere from 28% to 67%. (Note: 1 - 0.33 = 0.67 and 1 - 0.72 = 0.28.) 

We can add a column of log transformed antibody values to data frame instead of log transforming on-the-fly and then refit the model. This helps us create an effect plot.

```{r}
malaria$logab <- log(malaria$ab)
lrm <- glm(mal ~ age + logab, family = binomial(link = "logit"), data = malaria)
```

To create an effect plot for "logab" we can use the ggpredict() function from the ggeffects package. This plot basically shows the predicted probabilities of malaria over the range of observed log antibody levels, holding age at its mean level (in this case, around 9).

```{r}
library(ggeffects)
plot(ggpredict(model = lrm, terms = "logab [all]"))
```

We see the probability of being at risk of malaria drops pretty dramatically when logab is greater than 3, or transformed back to the original scale, when ab is exp(3) = 54.59, or about 55. The grey strip surronding the line is a 95% confidence ribbon that gives some indication of the uncertainty of our predictions. This ribbon is wider where we have less data and more uncertainty.

Now we can assess the accuracy of the model we built. 

```{r}
anova(lrm, test = "Chisq")
```

If we wanted to, we could have split the data into training and testing data:

```{r}
set.seed(1)  # make reproducible
i <- sample(x = nrow(malaria), size = 0.75*floor(nrow(malaria)))
malaria.train <- malaria[i,]
malaria.test <- malaria[-i,]
```

We can then test our model on the training data and see how well it performs. 

```{r}
prediction <- predict(lrm, newdata = malaria.test, type="response")
```

### Logistic regression with numeric predictors (2)

The `pima` data frame from the faraway package contains data on 768 adult female Pima Indians living near Phoenix [@faraway]. This data was collected by [The National Institute of Diabetes and Digestive and Kidney Diseases](https://www.niddk.nih.gov/). The purpose of the study was to investigate factors related to diabetes. The variable "test" indicates whether the patient showed signs of diabetes (coded 0 if negative, 1 if positive). Model test as a function of all other predictors.

```{r}
library(faraway)
data("pima")
```

We can get quick statistical summaries of all the variables using the `summary()` function. 

```{r}
summary(pima)
```

The variables are as follows:

- pregnant: number of times a subject was pregnant
- glucose: plasma glucose concentration
- diastolic: diastolic blood pressure
- triceps: triceps skin fold thickness
- insulin: 2-hour serum insulin in units of $\mu U/ml$
- bmi: body mass index
- diabetes: diabetes pedigree function
- age: subject's age
- test: whether patient showed signs of diabetes (0 if negative, 1 if positive)

Looking at test, we can see that it ranges from 0 to 1. The mean of test is 0.349 which indicates that 34.9% of the data entries in test take the value of 1. In the context of this data set, this means that 34.9% of people in this study showed signs of diabetes. 

From the summary we can see that insulin is right-skewed. Insulin ranges from 0 to 846.0, and its median of 30.5 is much less than its mean of 79.8. The 3rd quartile of insulin is 127.2, meaning that 75% of the data is below 127.2. The maximum value of 846.0 may be an outlier.

Like our previous example, we can look at a box plot to see this skewness. 

```{r}
boxplot(insulin ~ test, data = pima)
```

Now let's build our logistic regression model using the `glm()` function. Setting `family = binomial(link = "logit")` in the argument specifies logistic regression. We can call `summary()` on our model to get a model summary.

```{r}
pima_model = glm(test ~ ., family = binomial(link = "logit"), data = pima)
summary(pima_model)
```

We can then assess the model fit using the `anova()` function and specify a Chi-Squared test in the argument.

```{r}
anova(pima_model, test = "Chisq")
```

To reiterate, this test helps us determine if a particular predictor helps to reduce the model deviance. The first line shows the null model containing only the intercept – it uses just the observed proportion of subjects with a positive diabetes test result. The second line shows the model including pregnant. We can see this second model reduced the residual deviance from 993.48 to 956.21. This indicates to us that pregnant is an important contributor to the model because it reduced the deviance by more than 1 or 2 units. We can see that including glucose gives a better fit ($\chi^2 = 171.260, p < .001$), and the deviance is reduced to 784.95.

Like we did in the above example, we can evaluate the model fit by comparing it to a saturated model. 

```{r}
vcdExtra::LRstats(pima_model)
```

Here, we see that the p-value is fairly large. This indicates that this model is likely good at predicting if a subject has diabetes given the predictors. 

We can also assess the model error by looking at a plot of residuals vs. “Hat-values”.

```{r}
car::influencePlot(pima_model)
```

Here we can see the 6 most extreme values labelled. We can take a look at them like this:

```{r}
pima[c(14, 229, 350, 454, 503, 707),]
```
We can see here that these 6 subjects all have either very high or very low values for the insulin predictor, 0, 744, and 846, and very high/low values for glucose as well. 

Further we can evaluate the model coefficients and confidence intervals:

```{r}
pima_model$coefficients 
```

```{r}
confint(pima_model)
```

The confidence intervals give us an idea of what we can expect as a reasonable range of values for each predictor. For example we can see that the reasonable range of values for diabetes is from about 0.365 to about 1.539. This range is somewhat large and entirely positive, which indicates to us that diabetes has a positive effect on test. 


The interval for insulin, on the other hand, includes negative and positive values which means we can't tell if the effect is negative or positive. The range is small so we know the effect of insulin is small compared to diabetes. 

To get odds ratios of showing signs of diabetes to the odds of not showing signs of diabetes by exponentiating the confidence intervals. For example, 

```{r}
exp(confint(pima_model)["glucose",])
```

The odds ratios here are larger than one, which indicates that as the glucose predictor increases, the odds of having a positive diabetes result (test = 1) increases. For every unit increase in glucose, the odds of having diabetes increases anywhere from 2.85% to 4.37%. 

We can create an effect plot for glucose using `ggpredict()` from the `ggeffects` package:

```{r}
library(ggeffects)
plot(ggpredict(model = pima_model, terms = "glucose [all]"))
```

This plot shows the predicted probabilities of having diabetes (test) over the range of observed glucose values. It holds the remaining predictors at their mean values. 

We can see that the probability of having diabetes (test = 1) increases more quickly when the glucose levels is around 75 and above. The grey ribbon surrounding the solid black line is the 95% confidence ribbon and gives us an idea about the uncertainty of the model predictions -- a wider ribbon indicates more uncertainty. We can see that we have more uncertainty with larger glucose values. 

### Logistic regression with numeric and categorical predictors

The text _Applied Logistic Regression (3rd Ed)_ [@hosmer2013] presents data on women who were tracked as part of the Global Longitudinal Study of Osteoporosis in Women (GLOW). The GLOW data has information on 500 women, 125 of whom had a fracture during the first year of follow-up. One goal of this study was to evaluate risk factors for fractures.

The data is available as a ".txt" file. Below we import the data using the `read.table()` function with `header=TRUE` since the first row contains column header names. We then select columns we want to analyze and convert all the variable names to lower case for convenience. 

```{r}
URL <- "https://raw.githubusercontent.com/uvastatlab/sme/main/data/GLOW500.txt"
glow <- read.table(URL, header = TRUE)
glow <- glow[,c("PRIORFRAC", "AGE", "WEIGHT", "PREMENO", "RATERISK", "FRACTURE")]
names(glow) <- tolower(names(glow))
```

The variables are as follows:

- priorfrac: history of prior fracture (1 = yes, 0 = no)
- age: age at enrollment
- weight: weight at enrollment in kilograms
- premeno: menopause before age 45 (1 = yes, 0 = no)
- raterisk: self-reported risk of fracture (1 = Less than others of the same age, 2 = Same as others of the same age, 3 = Greater than others of the same age)
- fracture: any fracture in first year (1 = yes, 0 = no)

Since raterisk, priorfrac, and premeno are categorical variables, let's format as these as factors with descriptive labels.

```{r}
glow$raterisk <- factor(glow$raterisk, labels = c("less", "same", "greater"))
glow$priorfrac <- factor(glow$priorfrac, labels = c("no", "yes"))
glow$premeno <- factor(glow$premeno, labels = c("no", "yes"))
```

We can now model fracture as a function of the other variables. (Hosmer and Lemeshow 2013, Chapter 2). We use the syntax `fracture ~ .` where the `.` indicates to the `glm` function that we are predicting `fracture` using all other variables in the `glow` dataframe.

```{r}
m <- glm(fracture ~  ., data = glow, family = binomial)
```

Similar to above, we can assess the fit of this model using the `LRstats()` function.

```{r}
vcdExtra::LRstats(m)
```

The null hypothesis of this test is that the model is no different from the saturated model. A small p-value provides evidence against the null. Here the p-value is pretty high, so we might have some confidence in using this model to estimate the probability of a fracture based on the indepedent variables.

To help understand the model, let's create effect displays. One way to get started is with the `effects` package [@effects]. Simply use the `allEffects()` function in combination with `plot()`:

```{r fig.width=9.5}
library(effects)
plot(allEffects(m))
```

This has produced 5 plots, one for each independent variable in the model. On the y-axis is the probability of fracture and on the x-axis is the value for each independent variable. The error bars and light blue ribbons indicate the 95% confidence intervals. It appears history of prior fracture, age, and self-reported risk are all positively associated with the probability of sustaining a fracture. The effects of weight and menopause before age 45 are less certain. 

We can see the probability estimates by looking at the object produced by `allEffects()`. For example, the estimated probability of a fracture for someone who had a prior fracture is about 0.33, assuming all other variables are held constant at their mean level. This is about 0.13 higher than the estimated probability for a fracture for those subjects who had no prior fracture.

```{r}
allEffects(m)
```

How certain are we about the estimated difference of 0.13 between those with and without prior fractures? We can use the emmeans package [@emmeans] to help investigate. Below we use the `emmeans()` function to compare the two estimated probabilities. The difference appears to be different from 0 which we infer from the large z ratio and small p-value. The `regrid = "response"` argument ensures the output is on the probability scale. The `revpairwise` keywords says to "reverse" the pairwise comparison and subtract "no" from "yes".

```{r}
library(emmeans)
emmeans(m, specs = revpairwise ~ priorfrac, regrid = "response")
```

We can pipe the function's output into `confint()` to get a 95% confidence interval on the difference in probabilities. It appears the data is consistent with a difference ranging from 0.0345 to 0.232.

```{r}
emmeans(m, specs = revpairwise ~ priorfrac, regrid = "response") |>
  confint()
```

It's important to note the above comparison is based on holding all other predictor variables at some fixed level, typically their mean value. We can use the `at` argument to specify at what levels to hold the other variables. For example, what's the difference in expected probability of fracture between those with and without prior fractures assuming the subject is age 60, weighs 70 kg, did not experience menopause before age 45, and has "same" self-reported risk?

```{r}
emmeans(m, specs = revpairwise ~ priorfrac, 
        regrid = "response",
        at = list(age = 60, weight = 70, 
                  premeno = "no", raterisk = "same")) |>
  confint()
```

We estimate the difference in probability to be about 0.11 with a 95% confidence interval of [0.0147, 0.196].

Since we did not incorporate non-linear effects or interactions, we can directly interpret the coefficients in the logistic regression model output. Below we extract just the coefficient table from the summary output and round to three decimal places.

```{r}
coef(summary(m)) |> round(3)
```

The coefficient for "priorfracyes" is the expected log-odds change in fracture when priorfrac = "yes". If we exponentiate this value we get an odds ratio. Below we exponentiate all coefficients and round to 3 decimal places. 

```{r}
coef(m) |> exp() |> round(3)
```

Assuming all other variables held constant, the odds of a fracture if you had a prior fracture is about 1.97 times higher than if you did not have a prior fracture. Likewise the odds of a fracture increase by a factor of about 1.05 for each year subjects get older, assuming all else held constant.

95% confidence intervals help us understand the uncertainty in the estimated odds ratios. We can get these using `confint()` on the model object.

```{r}
confint(m) |>
  exp() |>
  round(3)
```

It appears the odds ratio for priorfrac is plausibly between 1.223 and 3.167.

### Ordered logistic regression

The `Vietnam` data frame in the vcdExtra package [@vcdextra] contains survey data from 1967 on student opinions of the Vietnam War. Students were asked to indicate which policy out of A, B, C or D they supported. The response categories were:

- A: Defeat North Vietnam by widespread bombing and land invasion
- B: Maintain the present policy
- C: De-escalate military activity, stop bombing and begin negotiations
- D: Withdraw military forces immediately

These are ordered levels, moving from very pro-war (A) to anti-war (D). Fit a proportional odds model to the data, modeling `response` as a function of `sex`, `year`, and their interaction. [@friendly2016] This will require using the `weights` argument with the `polr()` function. [@MASS]

We load the vcdExtra package and then load the Vietnam data using the `data()` function. The `head()` function returns the first 6 rows of the data frame and shows the data structured as _one row per variable combination_. For example, the first row shows 13 Freshman Females selected response A.

```{r}
library(vcdExtra)
data("Vietnam")
head(Vietnam)
```

Let's label the response variable for ease of interpretation. We can do this with the `factor()` function. In addition we set `ordered = TRUE` to tell R this is an ordered categorical variable.

```{r}
Vietnam$response <- factor(Vietnam$response, 
                           labels = c("Defeat", "Maintain",
                                      "De-escalate", "Withdraw"),
                           ordered = TRUE)
```

The year variable is an integer ranging from 1 - 5, corresponding to Freshmen, Sophomore, Junior, Senior, and Grad student. Let's format that as a factor as well.

```{r}
Vietnam$year <- factor(Vietnam$year, labels = c("Freshman", "Sophomore",
                                                "Junior", "Senior", 
                                                "Grad student"))
```

The Freq column counts the number of responses for each combination of sex, year and response. We can use the `xtabs()` function to create tables to help us summarize and understand the data. One table of interest is simply a breakdown of responses across all years and both sexes. The syntax `Freq ~ response` says "sum Freq by response levels". We see most students preferred to De-escalate.

```{r}
xtabs(Freq ~ response, data = Vietnam)
```

We can pipe the table into `proportions()` to see a breakdown of proportions. The proportion preferring De-escalation is 0.42, or 42 percent.

```{r}
xtabs(Freq ~ response, data = Vietnam) |>
  proportions() |>
  round(2)
```

Counts of sexes and years can be obtained this way as well. Over 80% of respondents were Male.

```{r}
xtabs(Freq ~ sex, data = Vietnam) |>
  proportions() |>
  round(2)
```

A majority of respondents were Grad students.

```{r}
xtabs(Freq ~ year, data = Vietnam) |>
  proportions() |>
  round(2)
```

How do proportions of war response compare by sex? We can add the sex variable to the `xtabs()` syntax to get this information. Notice when we pipe into `proportions()` we enter `margin = 1` to specify we want proportions calculated along the first dimension, which is the rows. This shows that both sexes prefer to De-escalate, but that females prefer to De-escalate by a much wider margin.

```{r}
xtabs(Freq ~ sex + response, data = Vietnam) |>
  proportions(margin = 1) |>
  round(2)

```

Does preference depend on year of the student? Again we can modify the `xtabs()` syntax as we did before. This time we see a slight preference for Defeat in the Freshman group and a large proportion preferring Withdraw in the Grad student group. 

```{r}
xtabs(Freq ~ year + response, data = Vietnam) |>
  proportions(margin = 1) |>
  round(2)
```

We might want to look at response by year and sex. Below we only look at the Freshman group using the `subset` argument. We see Males prefer "Defeat" while Females prefer "De-escalate".

```{r}
xtabs(Freq ~ sex + response, data = Vietnam, 
      subset = year == "Freshman") |>
  proportions(margin = 1) |>
  round(2)

```

We can create a data frame for visualizing the response proportions for all years by removing the `subset` argument from `xtabs()` and setting `margin = c(1,3)` in the call to `proportions()`. This calculates proportions along the rows (1st dimension) within each year (3rd dimension). Piping into `as.data.frame(responseName = "Prop")` returns a data frame with a column called "Prop" containing the proportions for each male/female response within each year group. 

```{r}
v_df <- xtabs(Freq ~ sex + response + year, data = Vietnam) |>
  proportions(margin = c(1,3)) |>
  as.data.frame(responseName = "Prop")
```

We can now visualize the data using the ggplot2 package [@ggplot2]. Since the proportions have already been calculated we use the `geom_col()` function to create the bar charts. We see that Males preferred Defeat over all year groups while Females preferred De-escalate over all year groups. We also notice that as we move higher along the class groups, we see increasing support among Males for De-escalate and Withdraw policies.

```{r fig.width=9.5}
library(ggplot2)
ggplot(v_df) +
  aes(x = year, y = Prop, fill = sex) +
  geom_col(position = "dodge") +
  facet_wrap(~ response)
```

We now proceed to model the ordered categorical response as a function of sex, year and their interaction. We use the `polr()` function [@MASS] to fit a _proportional odds logistic regression model_. This models the _cumulative probabilities_ of the ordered response. We call the model _proportional_ because we assume the predictor effects are the same, _no matter what cumulative probability we consider_. For example, we assume the effect of sex is the same whether we consider $P(\text{response} <= \text{Maintain})$ or $P(\text{response} <= \text{De-escalate})$.

Before we begin, let's look at the observed _cumulative proportions_ of response by year and sex. We do this by applying the `cumsum()` function along the rows for each year using `apply(MARGIN = c(1,3), cumsum)`. Notice we need to use the `aperm()` function (Array Transposition) to rotate the results. The vector `c(2, 1, 3)` says to put the columns (2) on the rows, the rows (1) on the columns, and leave the strata (3) as is. We see, for example, that 0.42 of Freshman Females prefer "Maintain" or "Defeat", while 0.66 of Freshman Males prefer "Maintain" or "Defeat". The final columns are all 1s because all students prefer "Withdraw" or a lower response. It is these cumulative proportions that we will model.

```{r}
xtabs(Freq ~ sex + response + year, data = Vietnam) |>
  proportions(margin = c(1, 3)) |>
  apply(MARGIN = c(1, 3), cumsum) |> 
  round(2) |>
  aperm(c(2, 1, 3))
```

In the `polr()` code below we specify `weights = Freq` since our data is structured as one row per sex/year combination instead of one row per response, and we set `Hess = TRUE` to compute standard errors. 

```{r}
library(MASS)
m <- polr(response ~ sex * year, data = Vietnam, 
          weights = Freq, Hess = TRUE)
summary(m)
```

In the output we get one set of coefficients for the predictors but _three intercepts_ reflecting the three possible cumulative probabilities:

1. $P(\text{response} <= \text{Defeat})$
2. $P(\text{response} <= \text{Maintain})$
3. $P(\text{response} <= \text{De-escalate})$

By definition, the $P(\text{response} <= \text{Withdraw}) = 1$, so it is not modeled.

We can interpret the coefficients as _odds ratios_ by exponentiating them. An odds ratio is the odds of one event divided by the odds of another event. Odds are defined as $p/(1-p)$, where p is the probability of an event. For example, if the probability a Freshman Male prefers Defeat is 0.40, and the probability a Freshman Female prefers Defeat is 0.20, then the odds ratio is calculated as follows:

$$\frac{0.40/(1 - 0.40)}{0.20/(1 - 0.20)} = \frac{0.67}{0.25} = 2.67 $$

This says the odds that a Freshman Male prefers Defeat is about 2.67 times the the odds that a Freshman Female prefers Defeat.

The model output shows coefficients for Males and all years except Freshman. This implies the reference levels are Female and Freshman. Therefore exponentiating the coefficients will produce an odds ratio in comparison to Freshman Females. But since we have interactions, the main effect coefficients only apply to certain groups. For example: 

- the Male coefficient of -0.9778 applies to Freshman Males. 
- The Sophomore coefficient of 0.3859 applies to Sophomore Females. 
- The effect of Sophomore Males is the sum of the Male coefficient, the Sophomore coefficient, and their interaction: -0.9778 + 0.3859 + -0.2659 = -0.8578.

Exponentiating the Male coefficient returns an odds ratio of 0.376. This says the odds of Freshman Males preferring a certain response or lower is 1 - 0.376 = 0.624, or about 62% lower than the odds of Freshman Females preferring a certain response or lower. 

```{r}
exp(coef(m)["sexMale"])
```

Remember, we're modeling cumulative probabilities, hence the expression, "some response or lower". Also the coefficients apply to all responses. It doesn't matter whether we're considering "Maintain or lower" or "De-escalate or lower."

Likewise, exponentiating the sum of coefficients for Sophomore Males, -0.8578, returns an odds ratio of 0.424. This says the odds of Sophomore Males preferring a certain response or lower is 1 - 0.424 = 0.576, or about 58% lower than the odds of Freshman Females preferring a certain response or lower.

```{r}
vars <- c("sexMale", "yearSophomore", "sexMale:yearSophomore")
exp(sum(coef(m)[vars]))
```

We can also use the model to get estimated cumulative probabilities instead of odds ratios. For example, what is the estimated cumulative probability that Grad Student Females prefer De-escalate or lower? Using our model coefficients, we can write this out as follows:

$$P(\text{response} <= \text{De-escalate}) = 2.1677 - 0.4832$$
We subtract instead of add coefficients because that's how proportional odds models are defined. (see `?polr`) We use the `De-escalate|Withdraw` intercept because we're interested in the cumulative probability of De-escalate or lower. The result, 1.6845 is on the log odds scale. If we take the inverse logit using the `plogis()` function we get the result as a cumulative probability. (Note: we can use the `zeta` component of the model object to extract the intercepts.) The estimated cumulative probability is about 0.84. We estimate a high probability of a Grad student Female of preferring De-escalate or lower. 

```{r}
plogis(m$zeta["De-escalate|Withdraw"] - coef(m)["yearGrad student"])
```

To estimate the probability of preferring just the De-escalate response, we need to subtract the cumulative probability of preferring Maintain or lower. The result is about 0.53.

```{r}
plogis(m$zeta["De-escalate|Withdraw"] - coef(m)["yearGrad student"]) - 
  plogis(m$zeta["Maintain|De-escalate"] - coef(m)["yearGrad student"])
```

We can get the specific probabilities directly by using the `predict()` function with `type = "probs"`.

```{r}
predict(m, newdata = data.frame(sex = "Female", year = "Grad student"), 
        type = "probs" )
```

If we pipe the result into `cumsum()` we get the estimated probability for De-escalate that we calculated "by hand" above. 

```{r}
predict(m, newdata = data.frame(sex = "Female", year = "Grad student"), 
        type = "probs" ) |>
  cumsum()
```

Recall the assumption of proportional odds. Is this assumption plausible? There a few ways we can assess this. One is to carry out a test for proportional odds [@brant] using the `poTest()` function in the car package [@car]. For this to work we need to refit our model using data structured with one row _per response_. To convert our data frame to this structure, we can use the `uncount()` function from the tidyr package [@tidyr]. We then refit our model using `polr()` but this time without the weights argument. Notice the model estimated coefficients are identical to the first model. 

```{r}
library(tidyr)
Vietnam2 <- uncount(Vietnam, weights = Freq)
m2 <- polr(response ~ sex * year, data = Vietnam2, Hess = TRUE)
all.equal(coef(m2), coef(m))
```

Now we carry out the proportional odds test. A low p-value is evidence against the null hypothesis that the proportional odds assumption is satisfied. Several tests are computed:

- an overall test of the proportional odds assumption (in the first row)
- separate tests for each coefficient (all remaining rows)

The first column contains the coefficients for the `polr` model. The second, third, and fourth rows contain coefficients for a series of binary logistic regression models. For example, the second column shows the coefficients for modeling the binary response of Not Defeat vs Defeat.^[You can verify this by running `glm(response != "Defeat" ~  sex * year, data = Vietnam2, family = binomial)`] The general idea is that the coefficients should be roughly the same across the three binary logistic regressions and similar to the `polr` coefficient.

The Overall test is rejected but the tests for each predictor appear fine. This seems contradictory. However, Brant (1990) notes that "even if the [overall] test is sufficiently powerful to detect departures from proportionality, inspection of the individual components of the test statistic...may provide no clear indication as to the nature of the discrepancy detected." (page 1173)

```{r}
library(car)
poTest(m2)
```

Another approach to inspecting the proportional odds assumption is to look at the _differences of logits_ of the cumulative probabilities using the relative frequencies, as described in Venables and Ripley (2002, page 204). To begin we calculate the observed cumulative proportions for each of the 10 possible variable combinations. The result below shows cumulative proportions for the 10 combinations in the columns. 


```{r}
vietnam.cpr <- xtabs(Freq ~ sex + year + response, data = Vietnam) |>
  ftable(col.vars = "response") |>
  proportions(margin = 1) |>
  apply(MARGIN = 1, cumsum)
vietnam.cpr
```

Next we use the `qlogis()` function to convert to logits (ie, log odds) and then take the difference in logits between row 2 (Maintain) and row 1 (Defeat). We would like these differences to be about the same. The mean difference is about 1.14 and there doesn't seem to be too much deviance from it, with minimum of 0.85 and maximum of 1.28.

```{r}
vietnam.ld <- qlogis(vietnam.cpr[2,]) - qlogis(vietnam.cpr[1,])
sort(vietnam.ld)
summary(vietnam.ld)
```

We can also take the difference in logits between row 3 (De-Escalate) and row 2 (Maintain). The mean is about 2.9 with a bit more variability. 

```{r}
vietnam.ld <- qlogis(vietnam.cpr[3,]) - qlogis(vietnam.cpr[2,])
sort(vietnam.ld)
summary(vietnam.ld)
```

It appears the proportional odds assumption is mostly safe, though the Overall test result from the `poTest()` function may cause concern. However, Frank Harrell notes in his article, [Violation of Proportional Odds is Not Fatal](https://www.fharrell.com/post/po/) that "violations of the proportional odds assumption usually do not prevent the proportional odds model from providing a reasonable treatment effect assessment." We'll continue with the proportional odds model but note that the `clm()` function in the ordinal package and the `vglm()` function in the VGAM package allow the fitting of _partial_ proportional odds models. These models allow certain predictors to have multiple coefficients corresponding to the multiple intercepts. That is, the proportional odds assumption is relaxed for specified predictors.

As with any model that contains interactions, we should assess if the interaction is necessary. We can do this with the `Anova()` function from the car package. The large Chi-square statistic provides good evidence that the interaction is worth keeping in the model. This means the effect of year and sex on the survey response depend on each other. 

```{r}
Anova(m)
```

How do year and sex interact? We can explore this with an effect display. One way to create an effect display is to use the `ggeffect()` function in the ggeffects package [@ggeffects]. Below we generate a plot with year on the x-axis and sex as a grouping variable. We see the interaction most vividly in Males in the Defeat and De-escalate responses. The probability of responding "Defeat" _decreases_ as year increases, but the probability of responding "De-escalate" _increases_ as year increases. 

```{r fig.width=9.5}
library(ggeffects)
ggeffect(m, terms = c("year", "sex")) |> 
  plot()
```

Looking at the effect display we see varying differences in predicted probabilities between Males and Females. How can we quantify those differences? One way is using the emmeans package [@emmeans]. Below we calculate pairwise differences between Males and Females conditioned on year and response. Setting `mode = "prob"` returns probabilities and piping into `confint()` returns confidence intervals on the differences. Finally we use the emmeans `subset()` method to see differences in predicted probabilities for just response = 3, which corresponds to "De-escalate". We see differences greater than 0 for all years except Grad student.

```{r}
library(emmeans)
emm_polr <- emmeans(m, pairwise ~ sex | year * response, mode = "prob") |>
  confint()
subset(emm_polr$contrasts, response == 3)
```

In fact there appears to be no real difference between Males and Females when they're Grad Students. Notice below we set `at = list(year = "Grad student")` to restrict our comparisons to just Grad students.

```{r}
emm_polr2 <- emmeans(m, pairwise ~ sex | year * response, mode = "prob", 
                    at = list(year = "Grad student")) 
emm_polr2$contrasts
```



### References

