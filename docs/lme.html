<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Mixed-Effect Models</title>

<script src="site_libs/header-attrs-2.18/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistical Modeling Examples in R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lm.html">linear models</a>
    </li>
    <li>
      <a href="lrm.html">logistic regression models</a>
    </li>
    <li>
      <a href="cm.html">count models</a>
    </li>
    <li>
      <a href="lme.html">mixed-effect models</a>
    </li>
  </ul>
</li>
<li>
  <a href="about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Mixed-Effect Models</h1>

</div>


<div id="multilevel-model-two-levels" class="section level3">
<h3>Multilevel model: two levels</h3>
<p>The <code>eggprod</code> data in the faraway package contains data on
egg production. <span class="citation">(Faraway 2016)</span> Six pullets
(young hens) were placed into each of 12 pens. Four blocks were formed
from groups of 3 pens based on location. Three treatments were applied.
The number of eggs produced was recorded. Start by visualizing the
distribution of eggs produced split by blocks and treatment.</p>
<pre class="r"><code>library(faraway)
data(&quot;eggprod&quot;)

library(ggplot2)
# Plotting eggs by treat
ggplot(eggprod, aes(x=treat, y=eggs, color = treat)) +
  geom_point() +
  coord_flip() + # Flipping x and y coordinates to mimic Base R plotting
  theme_classic() # Using classic theme</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code># Plotting eggs by block
ggplot(eggprod, aes(x=block, y=eggs, color = block)) + 
  geom_point() + 
  coord_flip() +
  theme_classic() </code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<p>This shows visually that treatment O may have produced fewer eggs
than treatment F or E whose distributions are more similar and closer to
one another. The distributions of eggs produced by each block seem to
overlap and are very similar to one another.</p>
<p>Now, we model the number of eggs produced with <code>treat</code> as
a fixed effect and <code>block</code> as a random effect using the
<code>lmer()</code> function.</p>
<pre class="r"><code>library(lme4)
m &lt;- lmer(eggs ~ treat + (1|block), data = eggprod)</code></pre>
<p>We specified the formula within the <code>lmer()</code> function
following the format
<code>outcome ~ fixed effect + (random slope | random intercept)</code>.
The random slope is set to 1, therefore it is a fixed slope. In other
words, all cases will have the same slope estimated. The random
intercept is set as <code>block</code> which means that the intercept
will be allowed to vary by <code>block</code>. Before analyzing any
statistics on this model, we first need to confirm we have met all the
necessary assumptions. The mlmtools package <span
class="citation">(Laura Jamison, Jessica Mazen, and Erik Ruzek
2022)</span> offers a function called <code>mlm_assumptions()</code>
which will test all the appropriate assumptions for a multilevel
model.</p>
<pre class="r"><code>library(mlmtools)
m_assum &lt;- mlm_assumptions(m)
# Homogeneity of variance
m_assum$homo.test</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: model.Res2
##           Df  Sum Sq Mean Sq F value Pr(&gt;F)
## group      3  295471   98490  0.7357 0.5595
## Residuals  8 1070935  133867</code></pre>
<p>The output from the test of homogeneity of variance indicates that
this assumption has been met. <span class="math inline">\(p =
0.56\)</span> which is greater than .05, indicating that the residual
variation across clusters is not significantly different.</p>
<pre class="r"><code># Outliers
m_assum$outliers</code></pre>
<pre><code>## [1] &quot;No outliers detected.&quot;</code></pre>
<pre class="r"><code># Multicollinearity
m_assum$multicollinearity</code></pre>
<pre><code>## [1] &quot;Model contains fewer than 2 terms, multicollinearity cannot be assessed.\n&quot;</code></pre>
<p>No outliers were detected in the model and since we only have one
predictor multicollinearity is not necessary to test. The remaining
tests included in <code>m_assum</code> are plots we need to visually
inspect.</p>
<pre class="r"><code>m_assum$fitted.residual.plot</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>The first plot to investigate is the above Fitted vs. Residuals plot.
On the x-axis are the fitted (predicted) values and on the y-axis are
the residuals (error). A dashed line appears at Residuals = 0 to
represent where the model is perfectly predicting a value. What we look
for here is whether the residuals lie randomly around the 0 line or if a
pattern appears in relation to the predicted values. We would want this
distribution to appear rather parallel to the 0 line, indicating that
residuals are fairly comparable to one another. Lastly, no one point
should stand out from the rest. If one does, it means there is an
outlier and that one point is be drastically misestimated. All 3 of
these criteria are met in the above plot.</p>
<p>Lastly, we can investigate the assumption of residual normality.</p>
<pre class="r"><code>m_assum$resid.normality.plot</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The above QQ-plot compares the model residuals to a normal
distribution. Ideally, all points should be as close as possible to the
line and be evenly distributed around it (e.g., not all points are above
the line; points don’t form a curve below the line). We can see that the
points are randomly and evenly distributed around the line and can
assume we meet this assumption.</p>
<p>Now, we can inspect the model estimates and its overall fit. <span
class="citation">(Faraway 2006)</span> Does <code>treat</code> appear to
affect the number of eggs, and if so, which treatment seems superior? We
can look into this assessing both model fit and significance of
predictors. First, a summary of the model is useful to look at.</p>
<pre class="r"><code>summary(m)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: eggs ~ treat + (1 | block)
##    Data: eggprod
## 
## REML criterion at convergence: 85.4
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.71233 -0.47453 -0.02845  0.64196  1.42942 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  block    (Intercept) 129.9    11.40   
##  Residual             386.9    19.67   
## Number of obs: 12, groups:  block, 4
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   349.00      11.37  30.702
## treatF         -6.25      13.91  -0.449
## treatO        -42.50      13.91  -3.056
## 
## Correlation of Fixed Effects:
##        (Intr) treatF
## treatF -0.612       
## treatO -0.612  0.500</code></pre>
<p>Looking at the predictor, the fixed intercept, 349.00, is the mean
eggs when the treat factor is at its lowest level (treatE). The
intercept fixed effect is the grand mean of eggs across the entire
sample when treat = “E” (349.00). The treatF and treatO fixed effects
can be interpreted as the difference in means (e.g., treatE - treatF).
Therefore, treatF produces 6.25 less mean egg production and treatO
produces 42.50 less mean egg production.</p>
<p>This is further substantiated by looking at the means by treatment.
Observed means of eggs by treat:</p>
<pre class="r"><code>tapply(eggprod$eggs, eggprod$treat, mean)</code></pre>
<pre><code>##      E      F      O 
## 349.00 342.75 306.50</code></pre>
<p>We see that the means of treatment <code>E</code> and <code>F</code>
are closer to each other than either of them are to treatment
<code>O</code>. To test whether this effect is significant, there are
two options. We can use the <code>car::Anova</code> function, or load
the <code>lmerTest</code> package <span class="citation">(Kuznetsova,
Brockhoff, and Christensen 2017)</span>.</p>
<pre class="r"><code>car::Anova(m)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: eggs
##        Chisq Df Pr(&gt;Chisq)   
## treat 10.887  2   0.004324 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The <code>Anova()</code> function shows that the model including
treat is a better fit (<span class="math inline">\(\chi^2(2,N = 12) =
10.887, p &lt; .01\)</span>) than the null model (intercept only). This
tells us that this is a better fitting model, but does not provide
deeper information as to potential significant differences within levels
of our predictor. To investigate this, we can load <code>lmerTest</code>
package and rerun the model. This will add a significance marker to the
independent variables if they are significant.</p>
<pre class="r"><code>library(lmerTest)
m &lt;- lmer(eggs ~ treat + (1|block), data = eggprod)
summary(m)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: eggs ~ treat + (1 | block)
##    Data: eggprod
## 
## REML criterion at convergence: 85.4
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.71233 -0.47453 -0.02845  0.64196  1.42942 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  block    (Intercept) 129.9    11.40   
##  Residual             386.9    19.67   
## Number of obs: 12, groups:  block, 4
## 
## Fixed effects:
##             Estimate Std. Error     df t value Pr(&gt;|t|)    
## (Intercept)   349.00      11.37   7.99  30.702  1.4e-09 ***
## treatF         -6.25      13.91   6.00  -0.449   0.6690    
## treatO        -42.50      13.91   6.00  -3.056   0.0224 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##        (Intr) treatF
## treatF -0.612       
## treatO -0.612  0.500</code></pre>
<p>This shows that treatE and treatO are significantly different from
one another, but neither is significantly different from treatF. We can
further confirm this using pairwise comparisons, adjusted p-values and
confidence intervals:</p>
<pre class="r"><code>library(emmeans)
emmeans(m, pairwise ~ treat)</code></pre>
<pre><code>## $emmeans
##  treat emmean   SE   df lower.CL upper.CL
##  E        349 11.4 7.99      323      375
##  F        343 11.4 7.99      317      369
##  O        306 11.4 7.99      280      333
## 
## Degrees-of-freedom method: kenward-roger 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast estimate   SE df t.ratio p.value
##  E - F        6.25 13.9  6   0.449  0.8965
##  E - O       42.50 13.9  6   3.056  0.0508
##  F - O       36.25 13.9  6   2.606  0.0892
## 
## Degrees-of-freedom method: kenward-roger 
## P value adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<pre class="r"><code>emmeans(m, pairwise ~ treat) |&gt; confint()</code></pre>
<pre><code>## $emmeans
##  treat emmean   SE   df lower.CL upper.CL
##  E        349 11.4 7.99      323      375
##  F        343 11.4 7.99      317      369
##  O        306 11.4 7.99      280      333
## 
## Degrees-of-freedom method: kenward-roger 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast estimate   SE df lower.CL upper.CL
##  E - F        6.25 13.9  6  -36.426     48.9
##  E - O       42.50 13.9  6   -0.176     85.2
##  F - O       36.25 13.9  6   -6.426     78.9
## 
## Degrees-of-freedom method: kenward-roger 
## Confidence level used: 0.95 
## Conf-level adjustment: tukey method for comparing a family of 3 estimates</code></pre>
<p>We see that none of the mean differences are significant by treatment
group. However, the <code>t.ratio</code> is higher for <code>E-O</code>
and <code>F-O</code> than <code>E-F</code>. Visually we can also see
this using an effect plot:</p>
<pre class="r"><code>library(ggeffects)
ggpredict(m, terms = ~ treat) |&gt; plot(add.data = TRUE)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>This plot shows us the spread of predicted egg values based on their
treatment group. The black dot in the middle of each line represents the
prediction and the length of the line represents its 95% confidence
interval. The dots around each line represent the true data points. We
can see the same trend as indicated by their predicted value,
<code>E</code> and <code>F</code> are closer to one another than either
is to <code>O</code>, and we can also see that the spread of predicted
values for <code>O</code> overlaps with <code>E</code> and
<code>F</code>’s spreads.</p>
<p>Another statistic of interest for multilevel models is the Intraclass
Correlation Coefficient (ICC). The ICC tells us how strongly
observations within clusters are associated with one another. In other
words, it represents the correlation of any two units within a cluster.
To assess this, we can use the <code>ICCm</code> function from the
<code>mlmtools</code> package.</p>
<pre class="r"><code>ICCm(m)</code></pre>
<pre><code>## Likeness of eggs values of units in the same block factor: 0.251</code></pre>
<p>The likeness of egg production in the same block is .25, in other
words, the correlation between any two egg production observations
within the same block is .25. We can also look at what the variation is
between clusters using the <code>VarCorr()</code> function.</p>
<pre class="r"><code>VarCorr(m)</code></pre>
<pre><code>##  Groups   Name        Std.Dev.
##  block    (Intercept) 11.399  
##  Residual             19.670</code></pre>
<p>The variation around the random intercept for block is 11.40. We can
also look at the <span class="math inline">\(R^2\)</span> values for the
model to get an idea of how much variation in egg production is
explained. We can use the <code>rsqmlm()</code> function from the
<code>mlmtools</code> package to look at this.</p>
<pre class="r"><code>rsqmlm(m)</code></pre>
<pre><code>## 42.56% of the total variance is explained by the fixed effects.
## 57.00% of the total variance is explained by both fixed and random effects.</code></pre>
<p>We see that by including just the fixed effects, 42.56% of the
variance in egg production is explained. By including both the fixed and
random effects, the variance explained increases to 57%.</p>
</div>
<div id="repeated-measures-model" class="section level3">
<h3>Repeated-Measures model</h3>
<p>The book <em>Linear Mixed Models</em> presents a study on rat brains
<span class="citation">(West, Welch, and Galecki 2015)</span>. In this
study, five rats had three regions of their brains measured for
“activation” after two different treatments. Since all rats received
both treatments and had the same three regions measured both times, this
is a <em>repeated-measures</em> analysis. Of interest is how the numeric
dependent variable, activate, changes based on treatment and brain
region.</p>
<p>The data is available in the file “rat_brain.dat”. We can import this
file using the <code>read.table()</code> function. We set
<code>header = TRUE</code> because the first row of the data contains
column headers.</p>
<pre class="r"><code>rats &lt;- read.table(&quot;data/rat_brain.dat&quot;, header = TRUE)</code></pre>
<p>The animal column contains the id for each rat. Below we use the
<code>head()</code> function to view the first six rows of data. Notice
the first rat, R111097, has one measure for each combination of
treatment and region. This is why we refer to this as repeated-measures
data. Looking at the structure of the data, treatment and region are
being read in as integers. This means that if we were to use the data as
is, the model will interpret 0 as a meaningful value for each of these
variables. To avoid this, we will convert them both to factors.</p>
<pre class="r"><code>head(rats)</code></pre>
<pre><code>##    animal treatment region activate
## 1 R111097         1      1   366.19
## 2 R111097         1      2   199.31
## 3 R111097         1      3   187.11
## 4 R111097         2      1   371.71
## 5 R111097         2      2   302.02
## 6 R111097         2      3   449.70</code></pre>
<pre class="r"><code>str(rats)</code></pre>
<pre><code>## &#39;data.frame&#39;:    30 obs. of  4 variables:
##  $ animal   : chr  &quot;R111097&quot; &quot;R111097&quot; &quot;R111097&quot; &quot;R111097&quot; ...
##  $ treatment: int  1 1 1 2 2 2 1 1 1 2 ...
##  $ region   : int  1 2 3 1 2 3 1 2 3 1 ...
##  $ activate : num  366 199 187 372 302 ...</code></pre>
<pre class="r"><code>rats$treatment &lt;- as.factor(rats$treatment)
rats$region &lt;- as.factor(rats$region)</code></pre>
<p>We can start off plotting the data. The <code>stripplot()</code> from
the <code>lattice</code> package <span class="citation">(Sarkar
2008)</span> produces a one-dimensional scatterplot of the outcome
variable (activate) by rat.</p>
<pre class="r"><code>library(lattice)
stripplot(activate ~ animal, data=rats, scales=list(tck=0.5))</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>We can consider and fit several models with these data. The first
model will be the null model containing no predictors only a random
slope by animal. Then treatment will be introduced, treatment and
region, and then the interaction between treatment and region.</p>
<pre class="r"><code>m &lt;- lmer(activate ~ 1 + (1 | animal), data = rats)
m2 &lt;- lmer(activate ~ treatment + (1 | animal), data = rats)
m3 &lt;- lmer(activate ~ treatment + region + (1 | animal), data = rats)
m4 &lt;- lmer(activate ~ treatment*region + (1 | animal), data = rats)</code></pre>
<p>Now we can compare model fit. We’ll start by looking at the AIC
values for each model. Lower AIC value suggests a model will perform
better on out-of-sample data. These AIC values indicate that the model
containing the interaction between treatment and region is the best fit
for these data.</p>
<pre class="r"><code>AIC(m, m2, m3, m4)</code></pre>
<pre><code>##    df      AIC
## m   3 385.1023
## m2  4 355.0961
## m3  6 328.2485
## m4  8 291.2822</code></pre>
<p>We can also look to see how much more variance in activation is
explained by the model including the interaction than the null
model.</p>
<pre class="r"><code>varCompare(m, m4)</code></pre>
<pre><code>## m4 explains 70.93% more variance than m</code></pre>
<p>We see that the model including the interaction explains 70.93% more
variance than the null model. This is quite a large increase in variance
explained and supports this model being a good model for these data. We
can also look at the <span class="math inline">\(R^2\)</span> values for
the model containing the interaction. We see that 72.09% of the variance
is explained by the fixed effects (the interaction) and 90.63% of the
variance is explained by both the fixed and random effects.</p>
<pre class="r"><code>rsqmlm(m4)</code></pre>
<pre><code>## 72.09% of the total variance is explained by the fixed effects.
## 90.63% of the total variance is explained by both fixed and random effects.</code></pre>
<p>Now let’s interpret the model parameter estimates.</p>
<pre class="r"><code>summary(m4)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: activate ~ treatment * region + (1 | animal)
##    Data: rats
## 
## REML criterion at convergence: 275.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.4643 -0.5762  0.0802  0.4072  1.5509 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  animal   (Intercept) 4850     69.64   
##  Residual             2450     49.50   
## Number of obs: 30, groups:  animal, 5
## 
## Fixed effects:
##                    Estimate Std. Error t value
## (Intercept)          428.51      38.21  11.214
## treatment2            98.20      31.31   3.137
## region2             -190.76      31.31  -6.093
## region3             -216.21      31.31  -6.906
## treatment2:region2    99.32      44.27   2.243
## treatment2:region3   261.82      44.27   5.914
## 
## Correlation of Fixed Effects:
##             (Intr) trtmn2 regin2 regin3 trt2:2
## treatment2  -0.410                            
## region2     -0.410  0.500                     
## region3     -0.410  0.500  0.500              
## trtmnt2:rg2  0.290 -0.707 -0.707 -0.354       
## trtmnt2:rg3  0.290 -0.707 -0.354 -0.707  0.500</code></pre>
<p>Looking first at the fixed effects, the intercept (428.51) can be
interpreted as the grand mean of activate when treatment and region are
both 1 (the lowest level of each factor). The treatment2 estimate
(98.20) is the mean difference between treatment 2 and treatment 1 when
region is 1. Similarly, the region2 estimate (-190.76) is the mean
difference between region 2 and region 1 when treatment is 1, and
region3 (-216.21) is the mean difference between region 3 and region 2
when treatment is 1. The interaction terms require some calculation to
full interpret. Since we have two categorical predictors in this
interaction, we can interpret their coefficients in this way:</p>
<p><span class="math inline">\(\text{intercept} + \text{factor level
main effect 1} + \text{factor level main effect 2} + \text{interaction
effect}\)</span></p>
<p>For example, when looking at treatment2:region2 we will take the
values from the Estimates column that align with the following fixed
effects:</p>
<p><span class="math inline">\(\text{(Intercept)} + \text{treatment2} +
\text{region2} + \text{treatment2:region2}\)</span></p>
<p>Which gives us:</p>
<p><span class="math inline">\(428.51 + 98.20 - 190.76 + 99.32 =
435.27\)</span></p>
<p>This is also the mean of activate when treatment is 2 and region is
2:</p>
<pre class="r"><code>mean(rats[rats$treatment==&quot;2&quot; &amp; rats$region==&quot;2&quot;,&quot;activate&quot;])</code></pre>
<pre><code>## [1] 435.27</code></pre>
<p>We can do the same thing for treatment2:region3:</p>
<p><span class="math inline">\(428.51 + 98.20 - 216.21 + 261.82 =
572.32\)</span></p>
<p>Which is the mean of activate when treatment is 2 and region is
3:</p>
<pre class="r"><code>mean(rats[rats$treatment==&quot;2&quot; &amp; rats$region==&quot;3&quot;,&quot;activate&quot;])</code></pre>
<pre><code>## [1] 572.32</code></pre>
<p>To get a better understanding how this interaction is functioning,
let’s plot this model using the <code>ggeffects</code> package <span
class="citation">(Lüdecke 2018)</span>.</p>
<pre class="r"><code>library(ggeffects)
ggeffect(m4, terms = c(&quot;region&quot;, &quot;treatment&quot;)) |&gt;
         plot(add.data = TRUE, jitter = 0)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>This shows the relationship between treatment groups by region.
Within region one, the estimates for activate by treatment are closer
together, then in region 2 the estimate for treatment 1 and treatment 2
decrease while their magnitude of difference also increases. Then in
region 3 their magnitude of differences increases further as treatment 2
increases and treatment 1 decreases. This provides visual evidence that
the relationship between treatment groups changes based on the region.
We can use the <code>Anova()</code> function from the <code>car</code>
package <span class="citation">(Fox and Weisberg 2019)</span> to assess
the statistical significance of the visual evidence.</p>
<pre class="r"><code>car::Anova(m4)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: activate
##                    Chisq Df Pr(&gt;Chisq)    
## treatment        146.246  1  &lt; 2.2e-16 ***
## region            41.219  2  1.121e-09 ***
## treatment:region  35.649  2  1.815e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This indicates that the overall interaction is indeed significant.
However, we only know that an interaction exists, we must conduct
further comparison tests. We want to test the difference between
treatment levels within each region. The <code>contrast()</code>
function from the <code>emmeans</code> package <span
class="citation">(Lenth 2022)</span> allows us to do this. First, we
must create an emmeans object to pass to the <code>contrast()</code>
function. We will tell the <code>emmeans()</code> function which model
to use (m4) and which comparisons we want to test. To do this, we use
the <code>|</code> symbol to say test each treatment comparison by
region. Finally, since we are testing all pairwise comparisons we set
the adjust argument to “tukey” to use the Tukey post-hoc multiple
comparison adjustment.</p>
<pre class="r"><code>library(emmeans)
m4.emm &lt;- emmeans(m4, ~ treatment | region, adjust = &quot;tukey&quot;)
contrast(m4.emm)</code></pre>
<pre><code>## region = 1:
##  contrast          estimate   SE df t.ratio p.value
##  treatment1 effect    -49.1 15.7 20  -3.137  0.0052
##  treatment2 effect     49.1 15.7 20   3.137  0.0052
## 
## region = 2:
##  contrast          estimate   SE df t.ratio p.value
##  treatment1 effect    -98.8 15.7 20  -6.309  &lt;.0001
##  treatment2 effect     98.8 15.7 20   6.309  &lt;.0001
## 
## region = 3:
##  contrast          estimate   SE df t.ratio p.value
##  treatment1 effect   -180.0 15.7 20 -11.500  &lt;.0001
##  treatment2 effect    180.0 15.7 20  11.500  &lt;.0001
## 
## Degrees-of-freedom method: kenward-roger 
## P value adjustment: fdr method for 2 tests</code></pre>
<p>The output is split by each region. It tests each comparison and
within each region, therefore each region has two lines comparing
treatment 1 to treatment 2 and vice versa. Consequently, these lines
will conduct equivalent tests just with opposite signs in mean
differences. Looking at the “p.value” column, all pairwise comparisons
were significant. As we saw in the plot, the magnitude of difference
between treatment groups increases from region 1 (49.1) to region 2
(98.8) and then region 3 (180.0).</p>
</div>
<div id="longitudinal-model" class="section level3">
<h3>Longitudinal model</h3>
<p>The text <em>Statistical Methods for the Analysis of Repeated
Measurements</em> <span class="citation">(Davis 2002)</span> presents
data on plasma inorganic phosphate measurements for 33 subjects (13
controls, 20 obese) after an <a
href="https://www.mayoclinic.org/tests-procedures/glucose-challenge-test/about/pac-20394277">oral
glucose challenge</a>. Measurements were taken at baseline, 0.5, 1, 1.5,
2, and 3 hours. Of interest is how the plasma inorganic phosphate levels
differ over time and between the two groups. We present two models to
investigate these questions:</p>
<ul>
<li>a linear mixed-effect model</li>
<li>a generalized least squares model</li>
</ul>
<p>Below we read in the data, provide columns names, and format the
group column as a factor. Notice the data is in “wide” format, with one
record per subject.</p>
<pre class="r"><code>phosphate &lt;- read.table(&quot;data/phosphate.dat&quot;, header = FALSE)
names(phosphate) &lt;- c(&quot;group&quot;, &quot;id&quot;, &quot;t0&quot;, &quot;t0.5&quot;, &quot;t1&quot;, &quot;t1.5&quot;, &quot;t2&quot;, &quot;t3&quot;)
phosphate$group &lt;- factor(phosphate$group, labels = c(&quot;control&quot;, &quot;obese&quot;))
head(phosphate)</code></pre>
<pre><code>##     group id  t0 t0.5  t1 t1.5  t2  t3
## 1 control  1 4.3  3.3 3.0  2.6 2.2 2.5
## 2 control  2 3.7  2.6 2.6  1.9 2.9 3.2
## 3 control  3 4.0  4.1 3.1  2.3 2.9 3.1
## 4 control  4 3.6  3.0 2.2  2.8 2.9 3.9
## 5 control  5 4.1  3.8 2.1  3.0 3.6 3.4
## 6 control  6 3.8  2.2 2.0  2.6 3.8 3.6</code></pre>
<p>Reshaping the data facilitates data visualization. The
<code>pivot_longer()</code> function from the tidyr package makes quick
work of this. <span class="citation">(Wickham and Girlich
2022)</span></p>
<ul>
<li>The <code>names_to = "time"</code> argument moves the column names,
t0 - t3, into a single column called “time”</li>
<li>The <code>names_prefix = "t"</code> argument strips “t” from the
column names that were placed in the “time” column.</li>
<li>The <code>names_transform = list(time = as.numeric)</code> converts
values in the new “time” column to numeric.</li>
<li>The <code>values_to = "level"</code> moves the values under the t0 -
t3 columns into a single column called “level”</li>
</ul>
<pre class="r"><code>library(tidyr)
phosphateL &lt;- pivot_longer(phosphate, cols = t0:t3, 
                           names_to = &quot;time&quot;, 
                           names_prefix = &quot;t&quot;,
                           names_transform = list(time = as.numeric),
                           values_to = &quot;level&quot;)
head(phosphateL)</code></pre>
<pre><code>## # A tibble: 6 × 4
##   group      id  time level
##   &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 control     1   0     4.3
## 2 control     1   0.5   3.3
## 3 control     1   1     3  
## 4 control     1   1.5   2.6
## 5 control     1   2     2.2
## 6 control     1   3     2.5</code></pre>
<p>Now we can use the ggplot2 package <span class="citation">(Wickham
2016)</span> to visualize the data. Below we plot the phosphate
trajectories over time for each subject, with the plots broken out by
group. In addition we add a smooth trend line to each plot to visualize
the “average” trend for each group. There appears to be a great deal of
variability between the subjects within each group. It also looks like
the phosphate levels drop quickly within the first hour for the control
group compared to the obese group.</p>
<pre class="r"><code>library(ggplot2)
ggplot(phosphateL) +
  aes(x = time, y = level, group = id) +
  geom_line() +
  geom_smooth(aes(group = group), se = FALSE, linewidth = 2) +
  facet_wrap(~group)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>We can also compute simple means by time and group and compare
visually. Below we use <code>aggregate()</code> to compute the means and
then pipe into the ggplot code. Again it appears the phosphate levels
for the control group drop faster and lower than the obese group, though
by hour 3 they seem about the same.</p>
<pre class="r"><code>aggregate(level ~ time + group, data = phosphateL, mean) |&gt;
  ggplot() +
  aes(x = time, y = level, linetype = group) +
  geom_point() +
  geom_line()</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>In both plots it appears the effect of time differs between groups.
Therefore it seems reasonable to allow these terms to interact in our
mixed-effect model.</p>
<p>Before we begin modeling, we make the baseline phosphate measure a
predictor since a baseline measure is technically not a response to any
treatment or condition. <span class="citation">(Senn 2006)</span> To do
this we use <code>pivot_longer()</code> again but this time without
selecting column t0. When finished we rename the column as “baseline”.
We now have a column called “baseline” in our long data frame that we
will use as a predictor in our models.</p>
<pre class="r"><code>phosphateL &lt;- pivot_longer(phosphate, cols = t0.5:t3, 
                           names_to = &quot;time&quot;, 
                           names_prefix = &quot;t&quot;,
                           names_transform = list(time = as.numeric),
                           values_to = &quot;level&quot;)
names(phosphateL)[3] &lt;- &quot;baseline&quot;
head(phosphateL)</code></pre>
<pre><code>## # A tibble: 6 × 5
##   group      id baseline  time level
##   &lt;fct&gt;   &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 control     1      4.3   0.5   3.3
## 2 control     1      4.3   1     3  
## 3 control     1      4.3   1.5   2.6
## 4 control     1      4.3   2     2.2
## 5 control     1      4.3   3     2.5
## 6 control     2      3.7   0.5   2.6</code></pre>
<p>Finally we renumber group ids in the obese group to pick up where the
control group id numbering leaves off at 13.</p>
<pre class="r"><code>phosphateL$id &lt;- ifelse(phosphateL$group == &quot;obese&quot;, 
                        phosphateL$id + 13, 
                        phosphateL$id)</code></pre>
<div id="linear-mixed-effect-model" class="section level4">
<h4>Linear Mixed-Effect Model</h4>
<p>To fit our mixed-effect models we will use the <code>lmer()</code>
function in the lme4 package <span class="citation">(Bates et al.
2015)</span>. A mixed-effect model essentially allows us to fit separate
models to each subject. We assume each subject exerts some <em>random
effect</em> on certain model parameters. The most basic mixed-effect
model is the random intercept model, where each subject receives their
own intercept. This is the model we will fit.</p>
<p>Below we model level as a function of baseline (t0), time, group, and
the time:group interaction. We also fit a random intercept for each
subject using the syntax <code>(1|id)</code>. The summary output shows a
fairly large t value for the interaction, which provides good evidence
that the interaction is reliably negative. (The summary output for lmer
models does not display p values since the null distributions for the t
values are unknown for unbalanced data in the mixed-effect model
framework.)</p>
<pre class="r"><code>library(lme4)
m &lt;- lmer(level ~ baseline + time * group + (1|id), data = phosphateL)
summary(m, corr = FALSE)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: level ~ baseline + time * group + (1 | id)
##    Data: phosphateL
## 
## REML criterion at convergence: 269.1
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.33236 -0.58048 -0.00628  0.57732  2.45665 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 0.05685  0.2384  
##  Residual             0.23781  0.4877  
## Number of obs: 165, groups:  id, 33
## 
## Fixed effects:
##                 Estimate Std. Error t value
## (Intercept)      0.02284    0.37509   0.061
## baseline         0.68366    0.08465   8.076
## time             0.11310    0.07031   1.608
## groupobese       0.97883    0.18844   5.194
## time:groupobese -0.42850    0.09032  -4.744</code></pre>
<p>If we view the coefficients we see each subject has their own model,
but only the intercept varies between the subjects. Hence the reason we
call this a random-intercept model.</p>
<pre class="r"><code>head(coef(m)$id)</code></pre>
<pre><code>##   (Intercept)  baseline      time groupobese time:groupobese
## 1 -0.20776681 0.6836591 0.1130977  0.9788342      -0.4285031
## 2 -0.02798001 0.6836591 0.1130977  0.9788342      -0.4285031
## 3  0.11081072 0.6836591 0.1130977  0.9788342      -0.4285031
## 4  0.18347980 0.6836591 0.1130977  0.9788342      -0.4285031
## 5  0.11714532 0.6836591 0.1130977  0.9788342      -0.4285031
## 6  0.04369291 0.6836591 0.1130977  0.9788342      -0.4285031</code></pre>
<p>Before we use or interpret this model, we should assess the residuals
vs fitted value plot. We can create this plot by simply calling
<code>plot()</code> on the model object. We would like to see a uniform
distribution of residuals hovering closely around 0. This plot looks OK
for the most part.</p>
<pre class="r"><code>plot(m)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>The model we fit assumes the effect of time is <em>linear</em>, and
that the linear effect of time changes for each group. We can visualize
the model using the ggeffects package <span class="citation">(Lüdecke
2018)</span>. With the data added it seems like the linear effects may
be too simplistic.</p>
<pre class="r"><code>library(ggeffects)
ggeffect(m, terms = c(&quot;time&quot;, &quot;group&quot;)) |&gt;
  plot(add.data = TRUE, jitter = 0)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>Given our exploratory plots we may want to entertain a
<em>non-linear</em> effect of time. One way to do this is with natural
cubic splines. Using the splines package <span class="citation">(R Core
Team 2022)</span>, we can specify that we want to allow the trajectory
of time to change directions up to 3 times using the syntax
<code>ns(time, df = 3)</code>. We skip summarizing the model and look at
the residuals vs fitted value plot. This looks about the same as the
previous plot but a careful look at the y axis reveals we have slightly
smaller residuals.</p>
<pre class="r"><code>library(splines)
m2 &lt;- lmer(level ~ baseline + ns(time, df = 3) * group + (1|id), 
           data = phosphateL)
plot(m2)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>We can also examine the distribution of residuals by time within each
group using the syntax below. The plot shows residuals evenly
distributed and not too far from 0, which is good.</p>
<pre class="r"><code>plot(m2, resid(.) ~ time | group)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<p>Just as with linear models, we assume errors for a mixed-effect model
are drawn from a Normal distribution. A QQ plot helps us assess this
assumption. For models fit with lme4 we need to use the
<code>qqmath()</code> function from the lattice package <span
class="citation">(Sarkar 2008)</span> to create a QQ plot. The plot
below provides no reason for us to question this assumption.</p>
<pre class="r"><code>lattice::qqmath(m2)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<p>We can compare the models’ AIC values to assess whether the more
complicated non-linear model is better. Recall that lower AIC values
suggest a model will perform better on out-of-sample data. It appears
the model with non-linear effects is a good deal better than the model
with linear effects. The df column refers to the number of parameters in
the model.</p>
<pre class="r"><code>AIC(m, m2)</code></pre>
<pre><code>##    df      AIC
## m   7 283.0897
## m2 11 252.1101</code></pre>
<p>The non-linear model seems better than the original linear model. But
is the non-linear model a <em>good</em> model? One way to assess this is
to simulate data using the model and see how it compares to the original
data. Below we use the <code>simulate()</code> function to simulate 50
sets of phosphate values from our non-linear model. Next we plot a
smooth histogram of the observed data. Then we loop through the
simulated data and plot a smooth histogram for each simulation. What we
see is that our model is generating data that looks pretty similar to
our original data, though it seems to be a little off in the 3 - 4
range. It’s not perfect, and we wouldn’t want it to be, but it looks
good enough.</p>
<pre class="r"><code>sim1 &lt;- simulate(m2, nsim = 50)
plot(density(phosphateL$level), ylim = c(0, 0.6))
for(i in 1:50)lines(density(sim1[[i]]), col = &quot;grey90&quot;)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<p>As before, let’s use ggeffects to visualize our model. We see the
bend in our fitted lines due to the non-linear effects.</p>
<pre class="r"><code>ggeffect(m2, terms = c(&quot;time&quot;, &quot;group&quot;)) |&gt;
  plot(add.data = TRUE, jitter = 0)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<p>Looking at the summary for model m2 reveals coefficients that are
impossible to interpret. This is one of the drawbacks of models with
non-linear effects. However we see under the Random effects section that
there is more variation within subjects (0.4246) than between subjects
(0.2615).</p>
<pre class="r"><code>summary(m2, corr = FALSE)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: level ~ baseline + ns(time, df = 3) * group + (1 | id)
##    Data: phosphateL
## 
## REML criterion at convergence: 230.1
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.42067 -0.52371  0.07521  0.58973  2.49791 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 0.06836  0.2615  
##  Residual             0.18027  0.4246  
## Number of obs: 165, groups:  id, 33
## 
## Fixed effects:
##                              Estimate Std. Error t value
## (Intercept)                   0.47602    0.37259   1.278
## baseline                      0.68366    0.08465   8.076
## ns(time, df = 3)1             0.14832    0.23792   0.623
## ns(time, df = 3)2            -0.79764    0.28400  -2.809
## ns(time, df = 3)3             0.61529    0.15111   4.072
## groupobese                    0.56063    0.18006   3.114
## ns(time, df = 3)1:groupobese -1.15172    0.30561  -3.769
## ns(time, df = 3)2:groupobese -0.43565    0.36481  -1.194
## ns(time, df = 3)3:groupobese -1.14106    0.19411  -5.878</code></pre>
<p>Judging from the effect display the interaction in the model is
warranted, but we can formally test and verify this using the
<code>Anova()</code> function in the car package <span
class="citation">(Fox and Weisberg 2019)</span>. The large chi-square
statistic (37.6901) and small p-value confirm this.</p>
<pre class="r"><code>library(car)
Anova(m2)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II Wald chisquare tests)
## 
## Response: level
##                          Chisq Df Pr(&gt;Chisq)    
## baseline               65.2257  1  6.679e-16 ***
## ns(time, df = 3)       52.0478  3  2.926e-11 ***
## group                   5.8791  1    0.01532 *  
## ns(time, df = 3):group 37.6901  3  3.287e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Since we have both non-linear effects and interactions, there is no
convenient interpretation of our model parameters. However we can use
our model to make predictions at levels of interest and then compare the
expected values. For example, what is the expected difference in
phosphate values between control and obese subjects at 1 hour post
glucose challenge assuming a baseline value of 4? We can answer this
using the emmeans package <span class="citation">(Lenth 2022)</span>.
Below we specify we want to use model m2 and compare groups at time = 1
and baseline = 4, and then pipe into the <code>confint()</code> function
for a 95% confidence interval on the difference. (We can disregard the
note about interactions since we specified the time.) The output
indicates an estimated difference of about -0.825 with a 95% CI of
[-1.15, -0.502].</p>
<pre class="r"><code>library(emmeans)
emmeans(m2, specs = pairwise ~ group, 
        at = list(time = 1, baseline = 4)) |&gt;
  confint()</code></pre>
<pre><code>## $emmeans
##  group   emmean    SE   df lower.CL upper.CL
##  control   2.62 0.123 89.1     2.37     2.86
##  obese     3.44 0.109 73.2     3.22     3.66
## 
## Degrees-of-freedom method: kenward-roger 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast        estimate    SE   df lower.CL upper.CL
##  control - obese   -0.825 0.162 84.1    -1.15   -0.502
## 
## Degrees-of-freedom method: kenward-roger 
## Confidence level used: 0.95</code></pre>
</div>
<div id="generalized-least-squares-model" class="section level4">
<h4>Generalized Least Squares Model</h4>
<p>Another approach to analyzing longitudinal data is via Generalized
Least Squares (GLS) <span class="citation">(J. C. Pinheiro and Bates
2000)</span>. In this framework we do away with random effects and model
<em>correlated</em> errors. The nlme package that comes with R <span
class="citation">(J. Pinheiro, Bates, and R Core Team 2022)</span>
provides the <code>gls()</code> function for this task along with a
family of Correlation Structure Classes that allow us to model various
correlation structures.</p>
<p>To motivate the Generalized Least Squares approach, let’s ignore the
subject-level grouping structure and fit a linear model using the
<code>gls()</code> function.</p>
<pre class="r"><code>library(nlme)
m0 &lt;- gls(level ~ baseline + ns(time, df = 3) * group,
          data = phosphateL)</code></pre>
<p>Next we’ll investigate correlation of errors using a
<em>semivariogram</em>. Below we use the <code>Variogram()</code>
function from the nlme package and pipe the result into the
<code>plot()</code> function. The arguments
<code>form = ~ time | id</code> and <code>resType = "n"</code> says to
look at the “normalized” residuals over time by id. In addition we
specify <code>robust = TRUE</code> to reduce the influence of outliers.
The positive trend in the semivariogram values over “distance” indicate
the errors exhibit some correlation.</p>
<pre class="r"><code>Variogram(m0, form = ~ time | id, resType = &quot;n&quot;, robust = TRUE) |&gt;
  plot(span = 0.8)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<p>To help understand this, let’s extract the residuals from our linear
model, and then apply the <code>acf()</code> function to the residuals
by subject id. The <code>acf()</code> calculates autocorrelation at all
possible lags. We then extract the autocorrelation at lag 1 and sort by
absolute value. Notice that more than half the subjects have an
autocorrelation at lag 1 greater than 0.2 in absolute value.</p>
<pre class="r"><code>r &lt;- residuals(m0)
acf_out &lt;- tapply(r, phosphateL$id, acf, plot = FALSE)
lag1 &lt;- sapply(acf_out, function(x)x[1,1][[&quot;acf&quot;]])
mean(abs(lag1) &gt; 0.2)</code></pre>
<pre><code>## [1] 0.5757576</code></pre>
<p>Now we model this correlation using the <code>corCAR1()</code>
correlation structure. This will estimate a single correlation parameter
for the errors that will decrease exponentially with each lag. Notice
the model specification itself has not changed. We’ve simply added the
argument <code>correlation = corCAR1(form = ~ time | id)</code>.</p>
<pre class="r"><code>m3 &lt;- gls(level ~ baseline + ns(time, df = 3) * group,
          data = phosphateL,
          correlation = corCAR1(form = ~ time | id))</code></pre>
<p>Now the semivariogram shows no major patterns, suggesting the model
with the correlation structure is adequate.</p>
<pre class="r"><code>Variogram(m3, form = ~ time | id, resType = &quot;n&quot;, robust = TRUE) |&gt;
  plot(span = 0.8)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<p>In addition we can formally compare the models using the
<code>anova()</code> function. The large Likelihood Ratio test statistic
and difference in AIC/BIC values provides strong evidence against the
assumption of independent errors.</p>
<pre class="r"><code>anova(m0, m3)</code></pre>
<pre><code>##    Model df      AIC      BIC    logLik   Test  L.Ratio p-value
## m0     1 10 266.7059 297.2045 -123.3530                        
## m3     2 11 241.0958 274.6442 -109.5479 1 vs 2 27.61011  &lt;.0001</code></pre>
<p>Does our GLS model simulate data that is similar to our observed
data? To assess this we use the <code>simulate_lme()</code> function
from the nlraa package <span class="citation">(Miguez 2022)</span>.
(There is no simulate method included with the nlme package.) The
argument <code>psim = 2</code> specifies that the simulation use the
residual standard error and correlation pattern to generate uncertainty.
The result is encouraging.</p>
<pre class="r"><code>library(nlraa)
sim2 &lt;- simulate_lme(m3, psim = 2, nsim = 50)
plot(density(phosphateL$level), ylim = c(0, 0.6))
for(i in 1:50)lines(density(sim2[,i]), col = &quot;grey90&quot;)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<p>Let’s look at a summary of the model. We save the summary so we can
easily extract the estimated correlation parameter, called “Phi”. The
summary object is a list. The correlation parameter is contained within
the modelStruct element.</p>
<pre class="r"><code>m3_summary &lt;- summary(m3)
m3_summary$modelStruct$corStruct</code></pre>
<pre><code>## Correlation structure of class corCAR1 representing
##       Phi 
## 0.3026456</code></pre>
<p>The estimate of the correlation between two phosphate measurements
taken one hour apart on the same subject is about 0.302. The estimated
correlation for measurements two hours apart is <span
class="math inline">\(0.30265^2 = 0.0915\)</span>.</p>
<p>Calling <code>coef()</code> on the summary object returns the
coefficient table. Unlike the <code>lmer()</code> model, the
<code>gls()</code> model returns p-values for the marginal hypothesis
tests of the coefficients.</p>
<pre class="r"><code>coef(m3_summary)</code></pre>
<pre><code>##                                   Value  Std.Error   t-value      p-value
## (Intercept)                   0.4091347 0.38361051  1.066537 2.878289e-01
## baseline                      0.6976846 0.08699849  8.019502 2.356676e-13
## ns(time, df = 3)1             0.1572562 0.24999798  0.629030 5.302494e-01
## ns(time, df = 3)2            -0.7716235 0.28387468 -2.718184 7.307124e-03
## ns(time, df = 3)3             0.6129700 0.19036134  3.220034 1.559771e-03
## groupobese                    0.5689284 0.18739199  3.036034 2.809947e-03
## ns(time, df = 3)1:groupobese -1.1653201 0.32112822 -3.628831 3.853622e-04
## ns(time, df = 3)2:groupobese -0.4752147 0.36464363 -1.303230 1.944163e-01
## ns(time, df = 3)3:groupobese -1.1375232 0.24452357 -4.651998 6.969175e-06</code></pre>
<p>Notice the GLS coefficients are not terribly different from the
mixed-effect model coefficients.</p>
<pre class="r"><code># mixed-effect model coefficients
coef(summary(m2))</code></pre>
<pre><code>##                                Estimate Std. Error    t value
## (Intercept)                   0.4760242 0.37258684  1.2776195
## baseline                      0.6836591 0.08465065  8.0762412
## ns(time, df = 3)1             0.1483164 0.23791902  0.6233903
## ns(time, df = 3)2            -0.7976376 0.28400303 -2.8085533
## ns(time, df = 3)3             0.6152937 0.15111466  4.0717009
## groupobese                    0.5606301 0.18005581  3.1136460
## ns(time, df = 3)1:groupobese -1.1517234 0.30561251 -3.7685740
## ns(time, df = 3)2:groupobese -0.4356495 0.36480850 -1.1941868
## ns(time, df = 3)3:groupobese -1.1410573 0.19411030 -5.8783965</code></pre>
<p>Major differences between our mixed-effect model and GLS model are as
follows:</p>
<ul>
<li>The GLS model does not allow for subjects to have distinct
trajectories while the mixed-effect model does.</li>
<li>The GLS model does not estimate between-subject variability while
the mixed-effect model does.</li>
<li>The mixed-effect model assumes within-subject errors are independent
while the GLS model assumes they’re correlated.</li>
</ul>
<p>The within-subject errors for the mixed-effect model are assumed to
be drawn from a Normal distribution with mean 0 and standard deviation
of 0.42. The subject-specific random effects for the intercept are
assumed to be drawn from a Normal distribution with mean 0 and a
standard deviation of 0.26. We can extract these values using the
<code>VarCorr()</code> function.</p>
<pre class="r"><code>VarCorr(m2)</code></pre>
<pre><code>##  Groups   Name        Std.Dev.
##  id       (Intercept) 0.26145 
##  Residual             0.42459</code></pre>
<p>The within-subject errors for the GLS model are assumed to be drawn
from a multivariate Normal distribution with mean 0 and a
variance-covariance matrix with the specified correlation pattern. We
can extract this matrix using the <code>getVarCov()</code> function. The
standard deviations listed is the estimated residual standard error.</p>
<pre class="r"><code>getVarCov(m3)</code></pre>
<pre><code>## Marginal variance covariance matrix
##          [,1]     [,2]     [,3]     [,4]     [,5]
## [1,] 0.265340 0.145970 0.080305 0.044179 0.013370
## [2,] 0.145970 0.265340 0.145970 0.080305 0.024304
## [3,] 0.080305 0.145970 0.265340 0.145970 0.044179
## [4,] 0.044179 0.080305 0.145970 0.265340 0.080305
## [5,] 0.013370 0.024304 0.044179 0.080305 0.265340
##   Standard Deviations: 0.51512 0.51512 0.51512 0.51512 0.51512</code></pre>
<p>Using the <code>cov2cor()</code> function we can see the estimated
correlation pattern for the errors. Notice our Phi estimate, 0.30265,
appears two spots over from the diagonal. That’s because some of our
time measures are in half-hour increments.</p>
<pre class="r"><code>cov2cor(getVarCov(m3))</code></pre>
<pre><code>## Marginal variance covariance matrix
##          [,1]     [,2]    [,3]    [,4]     [,5]
## [1,] 1.000000 0.550130 0.30265 0.16650 0.050389
## [2,] 0.550130 1.000000 0.55013 0.30265 0.091594
## [3,] 0.302650 0.550130 1.00000 0.55013 0.166500
## [4,] 0.166500 0.302650 0.55013 1.00000 0.302650
## [5,] 0.050389 0.091594 0.16650 0.30265 1.000000
##   Standard Deviations: 1 1 1 1 1</code></pre>
<p>As with the mixed-effect model we should assess model fit, the
constant variance assumption, and normality of residuals. No pattern in
the residuals is evident and just about all the standardized residuals
are within 2 units of 0.</p>
<pre class="r"><code>plot(m3)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<p>The constant variance appears to hold at the 5 time points as
well.</p>
<pre class="r"><code>plot(m3, resid(.) ~ time | group)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<p>And the QQ plot of residuals gives no reason to doubt the assumption
of normality.</p>
<pre class="r"><code>qqnorm(m3)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<p>Once again we can use the ggeffects package to visualize our
model.</p>
<pre class="r"><code>ggeffect(m3, terms = c(&quot;time&quot;, &quot;group&quot;)) |&gt;
  plot(add.data = TRUE, jitter = 0)</code></pre>
<p><img src="lme_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>And using the emmeans package we can make comparisons at levels of
interest. For example, what is the expected difference in phosphate
values between control and obese subjects at 1 hour post glucose
challenge assuming a baseline value of 4? (We can disregard the note
about interactions since we specified the time.) The output indicates an
estimated difference of about -0.814 with a 95% CI of [-1.17, -0.457].
This is similar to what we obtained with the mixed-effect model.</p>
<pre class="r"><code>emmeans(m3, specs = pairwise ~ group, 
        at = list(time = 1, baseline = 4)) |&gt;
  confint()</code></pre>
<pre><code>## $emmeans
##  group   emmean    SE   df lower.CL upper.CL
##  control   2.62 0.137 86.2     2.35     2.89
##  obese     3.43 0.119 76.4     3.19     3.67
## 
## Degrees-of-freedom method: satterthwaite 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast        estimate   SE   df lower.CL upper.CL
##  control - obese   -0.814 0.18 83.2    -1.17   -0.457
## 
## Degrees-of-freedom method: satterthwaite 
## Confidence level used: 0.95</code></pre>
</div>
</div>
<div id="references" class="section level3 unnumbered">
<h3 class="unnumbered">References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-lme4" class="csl-entry">
Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015.
<span>“Fitting Linear Mixed-Effects Models Using <span
class="nocase">lme4</span>.”</span> <em>Journal of Statistical
Software</em> 67 (1): 1–48. <a
href="https://doi.org/10.18637/jss.v067.i01">https://doi.org/10.18637/jss.v067.i01</a>.
</div>
<div id="ref-davis" class="csl-entry">
Davis, Charles S. 2002. <em>Statistical Methods for the Analysis of
Repeated Measurements</em>. Springer, New York.
</div>
<div id="ref-faraway_book" class="csl-entry">
Faraway, Julian. 2006. <em>Extending the Linear Model with
<span>R</span></em>. CRC press. <a
href="https://julianfaraway.github.io/faraway/ELM/">https://julianfaraway.github.io/faraway/ELM/</a>.
</div>
<div id="ref-faraway" class="csl-entry">
———. 2016. <em>Faraway: Functions and Datasets for Books by Julian
Faraway</em>. <a
href="https://CRAN.R-project.org/package=faraway">https://CRAN.R-project.org/package=faraway</a>.
</div>
<div id="ref-car" class="csl-entry">
Fox, John, and Sanford Weisberg. 2019. <em>An <span>R</span> Companion
to Applied Regression</em>. Third. Thousand Oaks <span>CA</span>: Sage.
<a
href="https://socialsciences.mcmaster.ca/jfox/Books/Companion/">https://socialsciences.mcmaster.ca/jfox/Books/Companion/</a>.
</div>
<div id="ref-lmerTest" class="csl-entry">
Kuznetsova, Alexandra, Per B. Brockhoff, and Rune H. B. Christensen.
2017. <span>“<span class="nocase">lmerTest</span> Package: Tests in
Linear Mixed Effects Models.”</span> <em>Journal of Statistical
Software</em> 82 (13): 1–26. <a
href="https://doi.org/10.18637/jss.v082.i13">https://doi.org/10.18637/jss.v082.i13</a>.
</div>
<div id="ref-mlmtools" class="csl-entry">
Laura Jamison, Jessica Mazen, and Erik Ruzek. 2022. <em>Mlmtools:
Multi-Level Model Assessment Kit</em>. <a
href="https://CRAN.R-project.org/package=mlmtools">https://CRAN.R-project.org/package=mlmtools</a>.
</div>
<div id="ref-emmeans" class="csl-entry">
Lenth, Russell V. 2022. <em>Emmeans: Estimated Marginal Means, Aka
Least-Squares Means</em>. <a
href="https://CRAN.R-project.org/package=emmeans">https://CRAN.R-project.org/package=emmeans</a>.
</div>
<div id="ref-ggeffects" class="csl-entry">
Lüdecke, Daniel. 2018. <span>“Ggeffects: Tidy Data Frames of Marginal
Effects from Regression Models.”</span> <em>Journal of Open Source
Software</em> 3 (26): 772. <a
href="https://doi.org/10.21105/joss.00772">https://doi.org/10.21105/joss.00772</a>.
</div>
<div id="ref-nlraa" class="csl-entry">
Miguez, Fernando. 2022. <em>Nlraa: Nonlinear Regression for Agricultural
Applications</em>. <a
href="https://CRAN.R-project.org/package=nlraa">https://CRAN.R-project.org/package=nlraa</a>.
</div>
<div id="ref-nlmebook" class="csl-entry">
Pinheiro, José C., and Douglas M. Bates. 2000. <em>Mixed-Effects Models
in s and s-PLUS</em>. New York: Springer. <a
href="https://doi.org/10.1007/b98882">https://doi.org/10.1007/b98882</a>.
</div>
<div id="ref-nlme" class="csl-entry">
Pinheiro, José, Douglas Bates, and R Core Team. 2022. <em>Nlme: Linear
and Nonlinear Mixed Effects Models</em>. <a
href="https://CRAN.R-project.org/package=nlme">https://CRAN.R-project.org/package=nlme</a>.
</div>
<div id="ref-R" class="csl-entry">
R Core Team. 2022. <em>R: A Language and Environment for Statistical
Computing</em>. Vienna, Austria: R Foundation for Statistical Computing.
<a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-lattice" class="csl-entry">
Sarkar, Deepayan. 2008. <em>Lattice: Multivariate Data Visualization
with r</em>. New York: Springer. <a
href="http://lmdvr.r-forge.r-project.org">http://lmdvr.r-forge.r-project.org</a>.
</div>
<div id="ref-senn" class="csl-entry">
Senn, Stephen. 2006. <span>“Change from Baseline and Analysis of
Covariance Revisited,”</span> 4334–44.
</div>
<div id="ref-west2015" class="csl-entry">
West, Brady T., Kathleen B. Welch, and Andrzej T. Galecki. 2015.
<em>Linear Mixed Models, 2nd Ed.</em> Boca Raton: <span>CRC</span>
Press.
</div>
<div id="ref-ggplot2" class="csl-entry">
Wickham, Hadley. 2016. <em>Ggplot2: Elegant Graphics for Data
Analysis</em>. Springer-Verlag New York. <a
href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</div>
<div id="ref-tidyr" class="csl-entry">
Wickham, Hadley, and Maximilian Girlich. 2022. <em>Tidyr: Tidy Messy
Data</em>. <a
href="https://CRAN.R-project.org/package=tidyr">https://CRAN.R-project.org/package=tidyr</a>.
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
