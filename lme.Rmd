---
title: "Mixed-Effect Models"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
bibliography: refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

### Multilevel model: two levels

The `eggprod` data in the faraway package contains data on egg production. [@faraway] Six pullets (young hens) were placed into each of 12 pens. Four blocks were formed from groups of 3 pens based on location. Three treatments were applied. The number of eggs produced was recorded. Start by visualizing the distribution of eggs produced split by blocks and treatment. 

```{r}
library(faraway)
data("eggprod")

library(ggplot2)
# Plotting eggs ~ treat
ggplot(eggprod, aes(x=treat, y=eggs, color = treat)) + # Plotting eggs~treat, color by treat
  geom_jitter(position=position_jitter(0.2)) + # Creating a jitter plot,  staggering groups
  coord_flip() + # Flipping x and y coordinates to mimic Base R plotting
  theme_classic() # Using classic theme

# Plotting eggs ~ block
ggplot(eggprod, aes(x=block, y=eggs, color = block)) + # Plotting eggs~treat, color by treat
  geom_jitter(position=position_jitter(0.2)) + # Creating a jitter plot,  staggering groups
  coord_flip() + # Flipping x and y coordinates to mimic Base R plotting
  theme_classic() # Using classic theme
```


This shows visually that treatment O may have produced fewer eggs than treatment F or E whose distributions are more similar and closer to one another. The distributions of eggs produced by each block seem to overlap and are very similar to one another. 

Now, we  model the number of eggs produced with `treat` as a fixed effect and `block` as a random effect. [@faraway_book] Does `treat` appear to affect the number of eggs, and if so, which treatment seems superior?

```{r}
library(lme4)
m <- lmer(eggs ~ treat + (1|block), data = eggprod)
summary(m)

library(performance)
icc(m)

VarCorr(m)
```

The likeness of egg production in the same block is .25. The variation around the intercept is 11.40 across blocks. The intercept fixed effect is the grand mean of eggs across the entire sample when treat = "E". The treatF and treatO fixed effects can be interpreted as the difference in means (e.g., treatE - treatF). Therefore, treatF produces 6.25 less mean egg production and treatO produces 42.50 less mean egg production.

This is further substantiated by looking at the means by treatment. Observed means of eggs by treat:

```{r}
tapply(eggprod$eggs, eggprod$treat, mean)
```

Pairwise comparisons, adjusted p-values and confidence intervals:

```{r}
library(emmeans)
emmeans(m, pairwise ~ treat)
emmeans(m, pairwise ~ treat) |> confint()
```

An effect plot:

```{r}
library(ggeffects)
ggpredict(m, terms = ~ treat) |> plot(add.data = TRUE)
```

We can now assess model fit and significance of predictors.

```{r}
car::Anova(m)

library(lmerTest)
summary(m)
```

Running a $\chi^2$ test on the model, we see that the model including treat is a better fit ($\chi^2(2,N = 12) = 10.887, p < .01$) than the null model (intercept only). By loading the `lmerTest` package, we can see in the summary that specifically, treatment O is significant less than treatment E.

```{r}
# normality of residuals; looks good
lattice::qqmath(m)
# constant variance; one pretty big residual (model predicts about 335 but the observed value is closer to 300)
plot(m)
# constant variance within treatment levels; TreatF has a lot more variability
plot(m, treat ~ resid(.))
```


### Repeated-Measures model

The book _Linear Mixed Models_ presents a study on rat brains [@west2015]. In this study, five rats had three regions of their brains measured for "activation" after two different treatments. Since all rats received both treatments and had the same three regions measured both times, this is a _repeated-measures_ analysis. Of interest is how the numeric dependent variable, activate, changes based on treatment and brain region.

The data is available in the file "rat_brain.dat". We can import this file using the `read.table()` function. We set `header = TRUE` because the first row of the data contains column headers.

```{r}
rats <- read.table("data/rat_brain.dat", header = TRUE)
```

The animal column contains the id for each rat. Below we use the `head()` function to view the first six rows of data. Notice the first rat, R111097, has one measure for each combination of treatment and region. This is why we refer to this as repeated-measures data.

```{r}
head(rats)
```



### Longitudinal model

The text _Statistical Methods for the Analysis of Repeated Measurements_ [@davis] presents data on plasma inorganic phosphate measurements for 33 subjects (13 controls, 20 obese) after an [oral glucose challenge](https://www.mayoclinic.org/tests-procedures/glucose-challenge-test/about/pac-20394277). Measurements were taken at baseline (t0), 0.5, 1, 1.5, 2, and 3 hours. Of interest is how the plasma inorganic phosphate levels differ over time and between the two groups. Fit a sensible linear mixed-effect model to investigate these questions. 

Below we read in the data, provide columns names, and format the group column as a factor. Notice the data is in "wide" format, with one record per subject.

```{r}
phosphate <- read.table("data/phosphate.dat", header = FALSE)
names(phosphate) <- c("group", "id", "t0", "t0.5", "t1", "t1.5", "t2", "t3")
phosphate$group <- factor(phosphate$group, labels = c("control", "obese"))
head(phosphate)
```

Reshaping the data facilitates data visualization. The `pivot_longer()` function from the tidyr package makes quick work of this. [@tidyr] 

- The `names_to = "time"` argument moves the column names, t0 - t3, into a single column called "time" 
- The `names_prefix = "t"` argument strips "t" from the column names that were placed in the "time" column.
- The `names_transform = list(time = as.numeric)` converts values in the new "time" column to numeric.
- The `values_to = "level"` moves the values under the t0 - t3 columns into a single column called "level"


```{r}
library(tidyr)
phosphateL <- pivot_longer(phosphate, cols = t0:t3, 
                           names_to = "time", 
                           names_prefix = "t",
                           names_transform = list(time = as.numeric),
                           values_to = "level")
head(phosphateL, n = 10)
```

Now we can use the ggplot2 package [@ggplot2] to visualize the data. Below we plot the phosphate trajectories over time for each subject, with the plots broken out by group. In addition we add a smooth trend line to each plot to visualize the "average" trend for each group. There appears to be a great deal of variability between the subjects within each group. It also looks like the phosphate levels drop quickly within the first hour for the control group compared to the obese group.

```{r}
library(ggplot2)
ggplot(phosphateL) +
  aes(x = time, y = level, group = id) +
  geom_line() +
  geom_smooth(aes(group = group), se = FALSE, linewidth = 2) +
  facet_wrap(~group)
```

We can also compute simple means by time and group and compare visually. Below we use `aggregate()` to compute the means and then pipe into the ggplot code. Again it appears the phosphate levels for the control group drop faster and lower than the obese group, though by hour 3 they seem about the same. 

```{r}
aggregate(level ~ time + group, data = phosphateL, mean) |>
  ggplot() +
  aes(x = time, y = level, linetype = group) +
  geom_point() +
  geom_line()
```

In both plots it appears the effect of time differs between groups. Therefore it seems reasonable to allow these terms to interact in our mixed-effect model. 

To fit our models we will use the `lmer()` function in the lme4 package [@lme4]. Below we model level as a function of time, group, and their interaction. We also fit a random intercept for each subject using the syntax `(1|id:group)`. The reason we use `id:group` is because the id numbers are nested within each group. This creates 33 separate id groups. The summary output shows a fairly large t value for the interaction, which provides good evidence that the interaction is reliably negative. (The summary output for lmer models does not display p values since the null distributions for the t values are unknown for unbalanced data.)

```{r}
library(lme4)
m <- lmer(level ~ time * group + (1|id:group), data = phosphateL)
summary(m, corr = FALSE)
```

Before we use or interpret this model we should assess the residuals vs fitted value plot. We can create this plot by simply calling `plot()` on the model object. We would like to see a uniform distribution of residuals hovering closely around 0. This plot looks OK until our fitted values exceed 4.0, at which point we begin to under-predict. Most of the residuals are positive in this range, indicating our model-fitted values are systematically smaller than what we observed.

```{r}
plot(m)
```

The model we fit assumes the effect of time is _linear_, and that the linear effect of time changes for each group. We can visualize the model using the ggeffects package [@ggeffects]. With the data added we can see that linear effects seem to simplistic.

```{r}
library(ggeffects)
ggeffect(m, terms = c("time", "group")) |>
  plot(add.data = TRUE, jitter = 0)
```

Given our exploratory plots we may want to entertain a _non-linear_ effect of time. One way to do this is with natural cubic splines. Using the splines package [@R], we can specify that we want to allow the trajectory of time to change directions twice using the syntax `ns(time, df = 2)`. We skip summarizing the model and look at the residuals vs fitted value plot. This looks better than the previous plot, though it still exhibits some under-predicting in the higher end of the fitted values.


```{r}
library(splines)
m2 <- lmer(level ~ ns(time, df = 2) * group + (1|group:id), 
           data = phosphateL)
plot(m2)
```

We can compare the models' AIC values to assess whether the more complicated model is better. Recall that lower AIC values suggest a model will perform better on out-of-sample data. It appears the model with non-linear effects is a good deal better than the model with linear effects. The df column refers to the number of parameters in the model.

```{r}
AIC(m, m2)
```

The non-linear model is better than the original linear model. But is the non-linear model a _good_ model? One way to assess this is to simulate data using the model and see how it compares to the original data. Below we use the `simulate()` function to simulate 50 sets of phosphate values from our non-linear model. Next we plot a smooth histogram of the observed data. Then we loop through the simulated data and plot a smooth histogram for each simulation. What we see is that our model is generating data that looks pretty similar to our original data. It's not perfect, and we wouldn't want it to be, but it looks good enough. 

```{r}
sim1 <- simulate(m2, nsim = 50)
plot(density(phosphateL$level), ylim = c(0, 0.6))
for(i in 1:50)lines(density(sim1[[i]]), col = "grey90")
```

As before, let's use ggeffects to visualize our model. We see the bend in our fitted lines due to our non-linear model. 

```{r}
ggeffect(m2, terms = c("time", "group")) |>
  plot(add.data = TRUE, jitter = 0)
```

Looking at the summary for model m2 reveals coefficients that are impossible to interpret. This is one of the drawbacks of models with non-linear effects. However we see under the Random effects section that there is more variation between subjects (0.54) than within subjects (0.42). This probably makes biological sense. 

```{r}
summary(m2, corr = FALSE)
```

Judging from the effect display the interaction in the model is warranted, but we can formally test and verify this using the `Anova()` function in the car package [@car]. The large chi-square statistic and small p-value confirm this.

```{r}
library(car)
Anova(m2)
```

Since we have both non-linear effects and interactions, there is no convenient interpretation of our model parameters. However we can use our model to make predictions at levels of interest and then compare the expected values. For example, what is the expected difference in phosphate values between control and obese subjects at 1 hour post glucose challenge? We can answer this using the emmeams package [@emmeans]. Below we specify we want to use m2 and compare groups at time = 1, and then pipe into the `confint()` function for a 95% confidence interval on the difference. (We can disregard the note about interactions since we specified the time.) The output indicates an estimated difference of about -0.83 with a 95% CI of [-1.26, -0.40].

```{r}
library(emmeans)
emmeans(m2, specs = pairwise ~ group, at = list(time = 1)) |>
  confint()
```



### References
