---
title: "Linear Modeling"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
bibliography: refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```


### Linear model with no predictors (intercept only)

A new reading program is being evaluated at an elementary school. A random sample of 20 students were tested to determine reading speed. Speed was measured in minutes. [@ott2004]

```{r}
speed <- c(5, 7, 15, 12, 8, 7, 10, 11, 9, 13, 10, 6, 11, 8, 10, 8, 7, 6, 11, 8, 20)
```

Visualize distribution of data:

```{r}
hist(speed)
```


Find the mean of speed and a 95% confidence interval on the mean.

```{r}
t.test(speed)
```

To get just the confidence interval:

```{r}
tout <- t.test(speed)
tout$conf.int
```

This can also be found using an intercept-only linear model:

```{r}
m <- lm(speed ~ 1)
confint(m)
```

Does the sample appear to be from a Normal distribution? If so, the points in a QQ Plot should lie close to the diagonal line. See [this article](https://data.library.virginia.edu/understanding-q-q-plots/) for information on QQ Plots. This plot looks ok.

```{r}
qqnorm(speed)
qqline(speed)
```


Using the model output:

```{r}
plot(m, which = 2)
```

A couple of observations seem unusual: 1, 3, 21

```{r}
speed[c(1, 3, 21)]
```

There was a fast reader and a couple of slower readers.

If a Normal QQ Plot if your data looks suspect, try comparing it to other Normal QQ plots created with Normal data. Below we calculate the mean and standard deviation of our data, re-draw the original QQ Plot, and then generate 24 additional QQ plots from a Normal distribution with the same mean and standard deviation as our data. The QQ Plot of our observed data doesn't seem too difference from the QQ Plots of Normal data.

```{r}
m <- mean(speed)
s <- sd(speed)

op <- par(mar = c(2,2,1,1), mfrow = c(5,5))
qqnorm(speed, xlab = "", ylab = "", main = "")
qqline(speed)
for(i in 1:24){
  d <- rnorm(20, mean = m, sd = s)
  qqnorm(d, xlab = "", ylab = "", main = "")
  qqline(d)
}
par(op)
```


### Linear model with categorical predictors


The `schooldays` data frame from the HSAUR3 package has 154 rows and 5 columns. It contains data from a sociological study of Australian Aboriginal and white children. Model `absent` (number of days absent during school year) as a function of `race`, `gender`, `school` (school type), and `learner` (average or slow learner). [@hsaur3] 

```{r}
library(HSAUR3)
data("schooldays")
```

```{r}
# plots to look at data
library(ggplot2)
library(dplyr)

# histogram of absences
hist(schooldays$absent)

# bar plot of absences by gender
schooldays_by_gender = schooldays %>% 
  group_by(gender) %>% 
  summarise(absent = sum(absent))

ggplot(aes(x=gender, y=absent), data = schooldays_by_gender) +
geom_bar(stat = "identity")

# base r strip chart of absences by gender
stripchart(absent ~ gender, data = schooldays,
           ylab = 'number of absences', xlab = 'gender', 
           main = 'Stripchart of Absences by gender')

# ggplot strip chart of absences by gender
ggplot(schooldays, aes(x = gender, y = absent, color=learner)) +
  geom_jitter(position = position_jitter(0.2))
```

```{r}
m <- lm(absent ~ race + gender + school + learner, schooldays)
summary(m)
```
Residuals.
median should center around 0. it doesn't really.
min/max and q1 and q3 should have roughly the same absolute value. they do not. residuals seem to show skew towards overprediction

Coefficients
std err -- std error of the coefficient. what exactly does this mean? std error in the estimation
interpretation example: according to the model, being non-aboriginal contributes negatively to school absence.

which hypothesis test is being done here ?
so the hypothesis test is based only on the difference from 0 ? wouldn't some coefficients just naturally be closer to 0 than others ? i assume the test accounts for this ? how ? by dividing by the std error ? but even that would not account for measurements of a certain variable just naturally being close to 0.
how do you assess the usefulness of a variable without the p-value ? bc a coefficient's magnitude is related to the magnitude of the measurements, right ? i def see the appeal of normalizing coefficients now but i know you are not "suppossed" to do that.

Residual standard error
How is degrees of freedom calculated? n - num predictors ? i think it is something close to that ...
i assume residual standard error should be close to 0 ? closer to 0 means less spread ? why is residual std error a good measure of the model? it does not seem that useful to me. bc it does not say anything about direction, does it ?

r-squareds ? 
how relevant are these actually ? -- read that article

f-statistic: statistic for hypothesis test all coefficients (=0)

```{r}
plot(m, which = 1)
```

https://data.library.virginia.edu/diagnostic-plots/

Residual vs Fitted: "This plot shows if residuals have non-linear patterns."
I think residuals are supposed to center around 0 for a "good" model. If residuals center around horizontal line, then the good indication of no non-linear relationships.
If spread around horizontal line which is non-zero, then "bad" model with no non-linear relationships?

For this in particular, values seems generally centered around mostly horizontal line @ 0. Good amount of spread above 0 -- overpredicting. Does this mean the model is not so good? Perhaps need to look at other things

```{r}
plot(m, which = 2)
```

Normal Q-Q: shows if residuals are normally distributed

These residuals should fall along the straight line if residuals are normally distributed. why is this important ? indication of equal variance ?

Is normally distributed residuals a requirement for linear regression? i may be thinking of equal variance

These residuals deviate quite a but from the straight line, so I would say the residuals are not normally distributed. I am not sure if this particular shape has implications or if we can conclude anything from it?

```{r}
plot(m, which = 3)
```

Scale-Location/Spread-Location: "This plot shows if residuals are spread equally along the ranges of predictors" -- check assumption of equal variance

equal variance between what?

residuals should center around the same value (horizontal line). if not horizontal, then residuals change as predictors change. residuals should not be dependent on predictors.

this plot seems ok to me. residuals do not seem to change with predictors.

if residuals do change with predictors, would this be a reason to use a mixed-effect model ?

```{r}
plot(m, which = 5)
```

Residuals vs leverage: helps to find influential cases. "look for cases outside of a dashed line"

there do not seem to be any particularly influential cases in this model

### Linear model with categorical and numeric predictors

The `bp.obese` data frame from the ISwR package has 102 rows and 3 columns. It contains data from a random sample of Mexican-American adults in a small California town. Analyze blood pressure (`bp`) as a function of obesity (`obese`) and gender (`sex`). Here `obese` is a ratio of actual weight to ideal weight from New York Metropolitan Life Tables. [@ISwR] 

```{r}
library(ISwR)
data("bp.obese")
```

Summary of data.

```{r}
summary(bp.obese)
```



### References
