---
title: "Linear Modeling"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
bibliography: refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```


### Linear model with no predictors (intercept only)

A new reading program is being evaluated at an elementary school. A random sample of 20 students were tested to determine reading speed. Speed was measured in minutes. [@ott2004]

```{r}
speed <- c(5, 7, 15, 12, 8, 7, 10, 11, 9, 13, 10, 6, 11, 8, 10, 8, 7, 6, 11, 8, 20)
```

Visualize distribution of data:

```{r}
hist(speed)
```


Find the mean of speed and a 95% confidence interval on the mean.

```{r}
t.test(speed)
```

To get just the confidence interval:

```{r}
tout <- t.test(speed)
tout$conf.int
```

This can also be found using an intercept-only linear model:

```{r}
m <- lm(speed ~ 1)
confint(m)
#m$coefficients # prints out the intercept value aka the mean here 
```

Does the sample appear to be from a Normal distribution?

```{r}
qqnorm(speed)
qqline(speed)
```

The model does not appear to be from a normal distribution. Perhaps my interpretation of the QQ plot is not quite right ? Also, is it also appropriate to use a qq plot to asses normality ?

Using the model output:

```{r}
plot(m, which = 2)
```

A couple of observations seem unusual: 1, 3, 21

```{r}
speed[c(1, 3, 21)]
```

There was a fast reader and a couple of slower readers.


### Linear model with categorical predictors


The `schooldays` data frame from the HSAUR3 package has 154 rows and 5 columns. It contains data from a sociological study of Australian Aboriginal and white children. Model `absent` (number of days absent during school year) as a function of `race`, `gender`, `school` (school type), and `learner` (average or slow learner). [@hsaur3] 

```{r}
library(HSAUR3)
data("schooldays")
```

<<<<<<< HEAD
Here, I build the model then output just the coefficients then just the confidence intervals for each coefficient. 

```{r}
#lm(absent ~ race + gender + school + learner, schooldays)

m2 <- lm(absent ~ race + gender + school + learner, schooldays)
m2
m2$coefficients
confint(m2)
```

Next, I plot the residuals against fitted values by setting the `which` attribute of plot to 1. 

```{r}
plot(m2, which = 1)
```

A good model would have residuals centered around 0 (I think). The residuals here seem to be centered around 0, indicating this is a good model. 

Also, from my googling I found that the red line is a LOWESS (locally weighted scatterplot smoothing). It is bent which may indicate some deviation from linearity (if the LOWESS line is flat that is an indication that linear model is good for this data). Does this bend mean that linear model is not the best choice here? Or is it not bent enough to indicate a need for a different model? 

I think the line is relatively flat, so for this model I would say that the linear model is a good choice for this data. 

The residuals above 0 span a larger range than the residuals below 0. I'm not totally sure what this means for the model. 


Now I look at the qq plot using `which` = 2. 

```{r}
plot(m2, which = 2)
```

Q-Q plot indicates whether or not the data is normally distributed. If it does follow a normal distribution, the data points will fall on the 45 degree line (the dashed line in the above plot). Here, we see that the data points outputted by the model do not fall on the 45 degree line so it does not follow a normal distribution. 


Now I look at the Scale Location plot by setting `which` = 3.

```{r}
plot(m2, which = 3)
```

The Scale-Location plot helps us determine homoskedasticity -- the variance of the residuals is constant or in other words if the spread of residuals is equal at all fitted values. If the red line on this plot is horizontal and the points are randomly distributed above and below the line, then the residuals are spread out equally at all fitted values. Here, the line slopes slightly upward, but is mostly horizontal. Also, the data points do appear to be uniformly/randomly spread above and below the line for all fitted values. So I think homoskedasticity holds for this model.  

Next, we look at the Cook's Distance plot using `which` = 4. 

```{r}
plot(m2, which = 4)
```

Here, we see that observations 61, 77, and 111 are influential data points (I think outliers??). Let's look at these points: 

```{r}
schooldays$absent[61]
schooldays$absent[77]
schooldays$absent[111]
```


And finally, we look at the Residuals vs Leverage plot using `which` = 5. 

```{r}
plot(m2, which = 5)
```

This plot helps us identify 
=======
```{r}
# plots to look at data
library(ggplot2)
library(dplyr)

# histogram of absences
hist(schooldays$absent)

# bar plot of absences by gender
schooldays_by_gender = schooldays %>% 
  group_by(gender) %>% 
  summarise(absent = sum(absent))

ggplot(aes(x=gender, y=absent), data = schooldays_by_gender) +
geom_bar(stat = "identity")

# base r strip chart of absences by gender
stripchart(absent ~ gender, data = schooldays,
           ylab = 'number of absences', xlab = 'gender', 
           main = 'Stripchart of Absences by gender')

# ggplot strip chart of absences by gender
ggplot(schooldays, aes(x = gender, y = absent, color=learner)) +
  geom_jitter(position = position_jitter(0.2))
```

```{r}
m <- lm(absent ~ race + gender + school + learner, schooldays)
summary(m)
```
Residuals.
median should center around 0. it doesn't really.
min/max and q1 and q3 should have roughly the same absolute value. they do not. residuals seem to show skew towards overprediction

Coefficients
std err -- std error of the coefficient. what exactly does this mean? std error in the estimation
interpretation example: according to the model, being non-aboriginal contributes negatively to school absence.

which hypothesis test is being done here ?
so the hypothesis test is based only on the difference from 0 ? wouldn't some coefficients just naturally be closer to 0 than others ? i assume the test accounts for this ? how ? by dividing by the std error ? but even that would not account for measurements of a certain variable just naturally being close to 0.
how do you assess the usefulness of a variable without the p-value ? bc a coefficient's magnitude is related to the magnitude of the measurements, right ? i def see the appeal of normalizing coefficients now but i know you are not "suppossed" to do that.

Residual standard error
How is degrees of freedom calculated? n - num predictors ? i think it is something close to that ...
i assume residual standard error should be close to 0 ? closer to 0 means less spread ? why is residual std error a good measure of the model? it does not seem that useful to me. bc it does not say anything about direction, does it ?

r-squareds ? 
how relevant are these actually ? -- read that article

f-statistic: statistic for hypothesis test all coefficients (=0)

```{r}
plot(m, which = 1)
```

https://data.library.virginia.edu/diagnostic-plots/

Residual vs Fitted: "This plot shows if residuals have non-linear patterns."
I think residuals are supposed to center around 0 for a "good" model. If residuals center around horizontal line, then the good indication of no non-linear relationships.
If spread around horizontal line which is non-zero, then "bad" model with no non-linear relationships?

For this in particular, values seems generally centered around mostly horizontal line @ 0. Good amount of spread above 0 -- overpredicting. Does this mean the model is not so good? Perhaps need to look at other things

```{r}
plot(m, which = 2)
```

Normal Q-Q: shows if residuals are normally distributed

These residuals should fall along the straight line if residuals are normally distributed. why is this important ? indication of equal variance ?

Is normally distributed residuals a requirement for linear regression? i may be thinking of equal variance

These residuals deviate quite a but from the straight line, so I would say the residuals are not normally distributed. I am not sure if this particular shape has implications or if we can conclude anything from it?

```{r}
plot(m, which = 3)
```

Scale-Location/Spread-Location: "This plot shows if residuals are spread equally along the ranges of predictors" -- check assumption of equal variance

equal variance between what?

residuals should center around the same value (horizontal line). if not horizontal, then residuals change as predictors change. residuals should not be dependent on predictors.

this plot seems ok to me. residuals do not seem to change with predictors.

if residuals do change with predictors, would this be a reason to use a mixed-effect model ?

```{r}
plot(m, which = 5)
```

Residuals vs leverage: helps to find influential cases. "look for cases outside of a dashed line"

there do not seem to be any particularly influential cases in this model
>>>>>>> 32e7ad35c8d6691690ec3b99e65d04935e7a233e

### Linear model with categorical and numeric predictors

The `bp.obese` data frame from the ISwR package has 102 rows and 3 columns. It contains data from a random sample of Mexican-American adults in a small California town. Analyze blood pressure (`bp`) as a function of obesity (`obese`) and gender (`sex`). Here `obese` is a ratio of actual weight to ideal weight from New York Metropolitan Life Tables. [@ISwR] 

```{r}
library(ISwR)
data("bp.obese")
```

Summary of data.

```{r}
summary(bp.obese)
```

```{r}
m3 <- lm(bp ~ obese + sex, bp.obese)
m3
```

```{r}
m3$coefficients
confint(m3)
```

### References
